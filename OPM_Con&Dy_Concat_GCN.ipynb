{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "Y9xnmqW32Ys_",
        "outputId": "4dda01b1-fa99-4702-e88c-6c57ad28e580"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>medWDIR10</th>\n",
              "      <th>WLANDMASK</th>\n",
              "      <th>WHGT</th>\n",
              "      <th>WLAI</th>\n",
              "      <th>LAI</th>\n",
              "      <th>medWDIR</th>\n",
              "      <th>difWDIR</th>\n",
              "      <th>outageLength</th>\n",
              "      <th>binaryts</th>\n",
              "      <th>countts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>1</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>2.913192</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>99.984551</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>1</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>101.489599</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>1</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>89.999149</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>1</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>2.925068</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>-253.901195</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>1</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>2.947943</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>100.359308</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 395 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ...  medWDIR10 WLANDMASK  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...  72.641768         1   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...  68.455052         1   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...  65.798428         1   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...  74.041407         1   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...  74.038184         1   \n",
              "\n",
              "         WHGT      WLAI       LAI    medWDIR     difWDIR  outageLength  \\\n",
              "0  143.317993  2.913192  3.274934  72.641768   99.984551            48   \n",
              "1  113.597603  1.000000  3.307087  68.455052  101.489599            48   \n",
              "2   80.900375  1.000000  3.307087  65.798428   89.999149            48   \n",
              "3  150.076904  2.925068  3.274934  74.041407 -253.901195            48   \n",
              "4  123.888351  2.947943  3.274934  74.038184  100.359308            48   \n",
              "\n",
              "   binaryts  countts  \n",
              "0         0        0  \n",
              "1         0        0  \n",
              "2         0        0  \n",
              "3         1        1  \n",
              "4         1        1  \n",
              "\n",
              "[5 rows x 395 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.utils import set_random_seed\n",
        "\n",
        "\n",
        "df = pd.read_csv('Data/WRF4.2.2_4km_calibrationFile_Eversource_Rainwind_294events_2023-11-17_CT 12.18.32 PM.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bRadNP1T2g9Q",
        "outputId": "64838f75-cf67-41a7-9606-e657121d6580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group Label: 1, Event Code: CT-2005100800\n",
            "Group Label: 2, Event Code: CT-2005101512\n",
            "Group Label: 3, Event Code: CT-2005102418\n",
            "Group Label: 4, Event Code: CT-2006011706\n",
            "Group Label: 5, Event Code: CT-2006021700\n",
            "Group Label: 6, Event Code: CT-2006060700\n",
            "Group Label: 7, Event Code: CT-2006090118\n",
            "Group Label: 8, Event Code: CT-2006102000\n",
            "Group Label: 9, Event Code: CT-2006102800\n",
            "Group Label: 10, Event Code: CT-2007041506\n",
            "Group Label: 11, Event Code: CT-2008030800\n",
            "Group Label: 12, Event Code: CT-2008032100\n",
            "Group Label: 13, Event Code: CT-2008090600\n",
            "Group Label: 14, Event Code: CT-2008102506\n",
            "Group Label: 15, Event Code: CT-2008121100\n",
            "Group Label: 16, Event Code: CT-2008122406\n",
            "Group Label: 17, Event Code: CT-2008123006\n",
            "Group Label: 18, Event Code: CT-2009050906\n",
            "Group Label: 19, Event Code: CT-2009100700\n",
            "Group Label: 20, Event Code: CT-2009112800\n",
            "Group Label: 21, Event Code: CT-2009120300\n",
            "Group Label: 22, Event Code: CT-2010012500\n",
            "Group Label: 23, Event Code: CT-2010031300\n",
            "Group Label: 24, Event Code: CT-2010042818\n",
            "Group Label: 25, Event Code: CT-2010050806\n",
            "Group Label: 26, Event Code: CT-2010082212\n",
            "Group Label: 27, Event Code: CT-2010093006\n",
            "Group Label: 28, Event Code: CT-2010120100\n",
            "Group Label: 29, Event Code: CT-2011082800\n",
            "Group Label: 30, Event Code: CT-2011120700\n",
            "Group Label: 31, Event Code: CT-2011122712\n",
            "Group Label: 32, Event Code: CT-2012091800\n",
            "Group Label: 33, Event Code: CT-2012102806\n",
            "Group Label: 34, Event Code: CT-2013013012\n",
            "Group Label: 35, Event Code: CT-2013051106\n",
            "Group Label: 36, Event Code: CT-2013052312\n",
            "Group Label: 37, Event Code: CT-2013052506\n",
            "Group Label: 38, Event Code: CT-2013060712\n",
            "Group Label: 39, Event Code: CT-2013061306\n",
            "Group Label: 40, Event Code: CT-2013103112\n",
            "Group Label: 41, Event Code: CT-2013111900\n",
            "Group Label: 42, Event Code: CT-2013112612\n",
            "Group Label: 43, Event Code: CT-2014010606\n",
            "Group Label: 44, Event Code: CT-2014041400\n",
            "Group Label: 45, Event Code: CT-2014051600\n",
            "Group Label: 46, Event Code: CT-2014061800\n",
            "Group Label: 47, Event Code: CT-2014100700\n",
            "Group Label: 48, Event Code: CT-2014102200\n",
            "Group Label: 49, Event Code: CT-2014110118\n",
            "Group Label: 50, Event Code: CT-2015010800\n",
            "Group Label: 51, Event Code: CT-2015080600\n",
            "Group Label: 52, Event Code: CT-2015081106\n",
            "Group Label: 53, Event Code: CT-2015091018\n",
            "Group Label: 54, Event Code: CT-2015102806\n",
            "Group Label: 55, Event Code: CT-2015110606\n",
            "Group Label: 56, Event Code: CT-2015111212\n",
            "Group Label: 57, Event Code: CT-2015111818\n",
            "Group Label: 58, Event Code: CT-2015121418\n",
            "Group Label: 59, Event Code: CT-2016010918\n",
            "Group Label: 60, Event Code: CT-2016011518\n",
            "Group Label: 61, Event Code: CT-2016011912\n",
            "Group Label: 62, Event Code: CT-2016012800\n",
            "Group Label: 63, Event Code: CT-2016021300\n",
            "Group Label: 64, Event Code: CT-2016021518\n",
            "Group Label: 65, Event Code: CT-2016021918\n",
            "Group Label: 66, Event Code: CT-2016022818\n",
            "Group Label: 67, Event Code: CT-2016030100\n",
            "Group Label: 68, Event Code: CT-2016031706\n",
            "Group Label: 69, Event Code: CT-2016032818\n",
            "Group Label: 70, Event Code: CT-2016040706\n",
            "Group Label: 71, Event Code: CT-2016090400\n",
            "Group Label: 72, Event Code: CT-2016092318\n",
            "Group Label: 73, Event Code: CT-2016092818\n",
            "Group Label: 74, Event Code: CT-2016110306\n",
            "Group Label: 75, Event Code: CT-2016111106\n",
            "Group Label: 76, Event Code: CT-2016120812\n",
            "Group Label: 77, Event Code: CT-2016121200\n",
            "Group Label: 78, Event Code: CT-2016121500\n",
            "Group Label: 79, Event Code: CT-2016121718\n",
            "Group Label: 80, Event Code: CT-2016122400\n",
            "Group Label: 81, Event Code: CT-2017010100\n",
            "Group Label: 82, Event Code: CT-2017010418\n",
            "Group Label: 83, Event Code: CT-2017011006\n",
            "Group Label: 84, Event Code: CT-2017011706\n",
            "Group Label: 85, Event Code: CT-2017012306\n",
            "Group Label: 86, Event Code: CT-2017020112\n",
            "Group Label: 87, Event Code: CT-2017031018\n",
            "Group Label: 88, Event Code: CT-2017031606\n",
            "Group Label: 89, Event Code: CT-2017041212\n",
            "Group Label: 90, Event Code: CT-2017041612\n",
            "Group Label: 91, Event Code: CT-2017042506\n",
            "Group Label: 92, Event Code: CT-2017042900\n",
            "Group Label: 93, Event Code: CT-2017050200\n",
            "Group Label: 94, Event Code: CT-2017050506\n",
            "Group Label: 95, Event Code: CT-2017051300\n",
            "Group Label: 96, Event Code: CT-2017051500\n",
            "Group Label: 97, Event Code: CT-2017051806\n",
            "Group Label: 98, Event Code: CT-2017052506\n",
            "Group Label: 99, Event Code: CT-2017060506\n",
            "Group Label: 100, Event Code: CT-2017061600\n",
            "Group Label: 101, Event Code: CT-2017072400\n",
            "Group Label: 102, Event Code: CT-2017072900\n",
            "Group Label: 103, Event Code: CT-2017081806\n",
            "Group Label: 104, Event Code: CT-2017082912\n",
            "Group Label: 105, Event Code: CT-2017090300\n",
            "Group Label: 106, Event Code: CT-2017090512\n",
            "Group Label: 107, Event Code: CT-2017091918\n",
            "Group Label: 108, Event Code: CT-2017100900\n",
            "Group Label: 109, Event Code: CT-2017101506\n",
            "Group Label: 110, Event Code: CT-2017102400\n",
            "Group Label: 111, Event Code: CT-2017102912\n",
            "Group Label: 112, Event Code: CT-2017110606\n",
            "Group Label: 113, Event Code: CT-2017111000\n",
            "Group Label: 114, Event Code: CT-2017111612\n",
            "Group Label: 115, Event Code: CT-2017111818\n",
            "Group Label: 116, Event Code: CT-2017112206\n",
            "Group Label: 117, Event Code: CT-2017120512\n",
            "Group Label: 118, Event Code: CT-2017120906\n",
            "Group Label: 119, Event Code: CT-2017122218\n",
            "Group Label: 120, Event Code: CT-2018010406\n",
            "Group Label: 121, Event Code: CT-2018012312\n",
            "Group Label: 122, Event Code: CT-2018020418\n",
            "Group Label: 123, Event Code: CT-2018020706\n",
            "Group Label: 124, Event Code: CT-2018021718\n",
            "Group Label: 125, Event Code: CT-2018022418\n",
            "Group Label: 126, Event Code: CT-2018030200\n",
            "Group Label: 127, Event Code: CT-2018040412\n",
            "Group Label: 128, Event Code: CT-2018041600\n",
            "Group Label: 129, Event Code: CT-2018060306\n",
            "Group Label: 130, Event Code: CT-2018062800\n",
            "Group Label: 131, Event Code: CT-2018072200\n",
            "Group Label: 132, Event Code: CT-2018091000\n",
            "Group Label: 133, Event Code: CT-2018101112\n",
            "Group Label: 134, Event Code: CT-2018101512\n",
            "Group Label: 135, Event Code: CT-2018101706\n",
            "Group Label: 136, Event Code: CT-2018102100\n",
            "Group Label: 137, Event Code: CT-2018102706\n",
            "Group Label: 138, Event Code: CT-2018102900\n",
            "Group Label: 139, Event Code: CT-2018110300\n",
            "Group Label: 140, Event Code: CT-2018110612\n",
            "Group Label: 141, Event Code: CT-2018110900\n",
            "Group Label: 142, Event Code: CT-2018111306\n",
            "Group Label: 143, Event Code: CT-2018111518\n",
            "Group Label: 144, Event Code: CT-2018112612\n",
            "Group Label: 145, Event Code: CT-2018112812\n",
            "Group Label: 146, Event Code: CT-2018120300\n",
            "Group Label: 147, Event Code: CT-2018121712\n",
            "Group Label: 148, Event Code: CT-2018122106\n",
            "Group Label: 149, Event Code: CT-2018122800\n",
            "Group Label: 150, Event Code: CT-2019010100\n",
            "Group Label: 151, Event Code: CT-2019010512\n",
            "Group Label: 152, Event Code: CT-2019010900\n",
            "Group Label: 153, Event Code: CT-2019012318\n",
            "Group Label: 154, Event Code: CT-2019020800\n",
            "Group Label: 155, Event Code: CT-2019021212\n",
            "Group Label: 156, Event Code: CT-2019022012\n",
            "Group Label: 157, Event Code: CT-2019022500\n",
            "Group Label: 158, Event Code: CT-2019031000\n",
            "Group Label: 159, Event Code: CT-2019031512\n",
            "Group Label: 160, Event Code: CT-2019032200\n",
            "Group Label: 161, Event Code: CT-2019033100\n",
            "Group Label: 162, Event Code: CT-2019040300\n",
            "Group Label: 163, Event Code: CT-2019041218\n",
            "Group Label: 164, Event Code: CT-2019041912\n",
            "Group Label: 165, Event Code: CT-2019042606\n",
            "Group Label: 166, Event Code: CT-2019051000\n",
            "Group Label: 167, Event Code: CT-2019051300\n",
            "Group Label: 168, Event Code: CT-2019052312\n",
            "Group Label: 169, Event Code: CT-2019052812\n",
            "Group Label: 170, Event Code: CT-2019061306\n",
            "Group Label: 171, Event Code: CT-2019070606\n",
            "Group Label: 172, Event Code: CT-2019081312\n",
            "Group Label: 173, Event Code: CT-2019082812\n",
            "Group Label: 174, Event Code: CT-2019092312\n",
            "Group Label: 175, Event Code: CT-2019100312\n",
            "Group Label: 176, Event Code: CT-2019100700\n",
            "Group Label: 177, Event Code: CT-2019101000\n",
            "Group Label: 178, Event Code: CT-2019101612\n",
            "Group Label: 179, Event Code: CT-2019102218\n",
            "Group Label: 180, Event Code: CT-2019102700\n",
            "Group Label: 181, Event Code: CT-2019103112\n",
            "Group Label: 182, Event Code: CT-2019110712\n",
            "Group Label: 183, Event Code: CT-2019111200\n",
            "Group Label: 184, Event Code: CT-2019112718\n",
            "Group Label: 185, Event Code: CT-2019120906\n",
            "Group Label: 186, Event Code: CT-2019121318\n",
            "Group Label: 187, Event Code: CT-2020011106\n",
            "Group Label: 188, Event Code: CT-2020011606\n",
            "Group Label: 189, Event Code: CT-2020012512\n",
            "Group Label: 190, Event Code: CT-2020020700\n",
            "Group Label: 191, Event Code: CT-2020021300\n",
            "Group Label: 192, Event Code: CT-2020021812\n",
            "Group Label: 193, Event Code: CT-2020022700\n",
            "Group Label: 194, Event Code: CT-2020030318\n",
            "Group Label: 195, Event Code: CT-2020030618\n",
            "Group Label: 196, Event Code: CT-2020031300\n",
            "Group Label: 197, Event Code: CT-2020031906\n",
            "Group Label: 198, Event Code: CT-2020032818\n",
            "Group Label: 199, Event Code: CT-2020040218\n",
            "Group Label: 200, Event Code: CT-2020040912\n",
            "Group Label: 201, Event Code: CT-2020041300\n",
            "Group Label: 202, Event Code: CT-2020041718\n",
            "Group Label: 203, Event Code: CT-2020042112\n",
            "Group Label: 204, Event Code: CT-2020042406\n",
            "Group Label: 205, Event Code: CT-2020042612\n",
            "Group Label: 206, Event Code: CT-2020043018\n",
            "Group Label: 207, Event Code: CT-2020051512\n",
            "Group Label: 208, Event Code: CT-2020071012\n",
            "Group Label: 209, Event Code: CT-2020080406\n",
            "Group Label: 210, Event Code: CT-2020081612\n",
            "Group Label: 211, Event Code: CT-2020082900\n",
            "Group Label: 212, Event Code: CT-2020093000\n",
            "Group Label: 213, Event Code: CT-2020100706\n",
            "Group Label: 214, Event Code: CT-2020101206\n",
            "Group Label: 215, Event Code: CT-2020101612\n",
            "Group Label: 216, Event Code: CT-2020102906\n",
            "Group Label: 217, Event Code: CT-2020110112\n",
            "Group Label: 218, Event Code: CT-2020110200\n",
            "Group Label: 219, Event Code: CT-2020111100\n",
            "Group Label: 220, Event Code: CT-2020111512\n",
            "Group Label: 221, Event Code: CT-2020112218\n",
            "Group Label: 222, Event Code: CT-2020113000\n",
            "Group Label: 223, Event Code: CT-2020120500\n",
            "Group Label: 224, Event Code: CT-2021011518\n",
            "Group Label: 225, Event Code: CT-2021030118\n",
            "Group Label: 226, Event Code: CT-2021031200\n",
            "Group Label: 227, Event Code: CT-2021031412\n",
            "Group Label: 228, Event Code: CT-2021031812\n",
            "Group Label: 229, Event Code: CT-2021032506\n",
            "Group Label: 230, Event Code: CT-2021032600\n",
            "Group Label: 231, Event Code: CT-2021032812\n",
            "Group Label: 232, Event Code: CT-2021041506\n",
            "Group Label: 233, Event Code: CT-2021042112\n",
            "Group Label: 234, Event Code: CT-2021042500\n",
            "Group Label: 235, Event Code: CT-2021042918\n",
            "Group Label: 236, Event Code: CT-2021052900\n",
            "Group Label: 237, Event Code: CT-2021070118\n",
            "Group Label: 238, Event Code: CT-2021070806\n",
            "Group Label: 239, Event Code: CT-2021072918\n",
            "Group Label: 240, Event Code: CT-2021081900\n",
            "Group Label: 241, Event Code: CT-2021082206\n",
            "Group Label: 242, Event Code: CT-2021090100\n",
            "Group Label: 243, Event Code: CT-2021090112\n",
            "Group Label: 244, Event Code: CT-2021090812\n",
            "Group Label: 245, Event Code: CT-2021100318\n",
            "Group Label: 246, Event Code: CT-2021101612\n",
            "Group Label: 247, Event Code: CT-2021102600\n",
            "Group Label: 248, Event Code: CT-2021102918\n",
            "Group Label: 249, Event Code: CT-2021111118\n",
            "Group Label: 250, Event Code: CT-2021111318\n",
            "Group Label: 251, Event Code: CT-2021111818\n",
            "Group Label: 252, Event Code: CT-2021112200\n",
            "Group Label: 253, Event Code: CT-2021112606\n",
            "Group Label: 254, Event Code: CT-2021120600\n",
            "Group Label: 255, Event Code: CT-2021121112\n",
            "Group Label: 256, Event Code: CT-2022020718\n",
            "Group Label: 257, Event Code: CT-2022021712\n",
            "Group Label: 258, Event Code: CT-2022022212\n",
            "Group Label: 259, Event Code: CT-2022030706\n",
            "Group Label: 260, Event Code: CT-2022031206\n",
            "Group Label: 261, Event Code: CT-2022031906\n",
            "Group Label: 262, Event Code: CT-2022032400\n",
            "Group Label: 263, Event Code: CT-2022033106\n",
            "Group Label: 264, Event Code: CT-2022033112\n",
            "Group Label: 265, Event Code: CT-2022040518\n",
            "Group Label: 266, Event Code: CT-2022040706\n",
            "Group Label: 267, Event Code: CT-2022041818\n",
            "Group Label: 268, Event Code: CT-2022050400\n",
            "Group Label: 269, Event Code: CT-2022050700\n",
            "Group Label: 270, Event Code: CT-2022051906\n",
            "Group Label: 271, Event Code: CT-2022090418\n",
            "Group Label: 272, Event Code: CT-2022092306\n",
            "Group Label: 273, Event Code: CT-2022100106\n",
            "Group Label: 274, Event Code: CT-2022100400\n",
            "Group Label: 275, Event Code: CT-2022101300\n",
            "Group Label: 276, Event Code: CT-2022101306\n",
            "Group Label: 277, Event Code: CT-2022111112\n",
            "Group Label: 278, Event Code: CT-2022112712\n",
            "Group Label: 279, Event Code: CT-2022113006\n",
            "Group Label: 280, Event Code: CT-2022120300\n",
            "Group Label: 281, Event Code: CT-2022120612\n",
            "Group Label: 282, Event Code: CT-2022121100\n",
            "Group Label: 283, Event Code: CT-2022121518\n",
            "Group Label: 284, Event Code: CT-2022122218\n",
            "Group Label: 285, Event Code: CT-2023010318\n",
            "Group Label: 286, Event Code: CT-2023011212\n",
            "Group Label: 287, Event Code: CT-2023011900\n",
            "Group Label: 288, Event Code: CT-2023012218\n",
            "Group Label: 289, Event Code: CT-2023012512\n",
            "Group Label: 290, Event Code: CT-2023020218\n"
          ]
        }
      ],
      "source": [
        "df = df.iloc[:236350, :]\n",
        "event_codes = df[\"eventCode\"]\n",
        "group_labels = np.zeros(len(df), dtype=int)\n",
        "\n",
        "current_label = 0\n",
        "previous_code = None\n",
        "\n",
        "for i, code in enumerate(event_codes):\n",
        "    if code != previous_code:\n",
        "        current_label += 1\n",
        "        previous_code = code\n",
        "    group_labels[i] = current_label\n",
        "\n",
        "unique_codes, unique_indices = np.unique(event_codes, return_index=True)\n",
        "for code, index in zip(unique_codes, unique_indices):\n",
        "    print(f\"Group Label: {group_labels[index]}, Event Code: {code}\")\n",
        "\n",
        "df[\"groupLabel\"] = group_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "onz2YEbi51eK",
        "outputId": "fc049769-3860-48b0-cc69-7b160896efc4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b48f0e7d-2ce5-409b-bab8-c4a0169678b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>WLANDMASK</th>\n",
              "      <th>WHGT</th>\n",
              "      <th>WLAI</th>\n",
              "      <th>LAI</th>\n",
              "      <th>medWDIR</th>\n",
              "      <th>difWDIR</th>\n",
              "      <th>outageLength</th>\n",
              "      <th>binaryts</th>\n",
              "      <th>countts</th>\n",
              "      <th>groupLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>2.913192</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>99.984551</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>101.489599</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>89.999149</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>2.925068</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>-253.901195</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>2.947943</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>100.359308</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 396 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b48f0e7d-2ce5-409b-bab8-c4a0169678b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b48f0e7d-2ce5-409b-bab8-c4a0169678b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b48f0e7d-2ce5-409b-bab8-c4a0169678b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35c84150-3108-41bb-91cc-c30acad3c029\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35c84150-3108-41bb-91cc-c30acad3c029')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35c84150-3108-41bb-91cc-c30acad3c029 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ... WLANDMASK        WHGT  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...         1  143.317993   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...         1  113.597603   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...         1   80.900375   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...         1  150.076904   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...         1  123.888351   \n",
              "\n",
              "       WLAI       LAI    medWDIR     difWDIR  outageLength  binaryts  countts  \\\n",
              "0  2.913192  3.274934  72.641768   99.984551            48         0        0   \n",
              "1  1.000000  3.307087  68.455052  101.489599            48         0        0   \n",
              "2  1.000000  3.307087  65.798428   89.999149            48         0        0   \n",
              "3  2.925068  3.274934  74.041407 -253.901195            48         1        1   \n",
              "4  2.947943  3.274934  74.038184  100.359308            48         1        1   \n",
              "\n",
              "   groupLabel  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "\n",
              "[5 rows x 396 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "XaGEEz3i4nXF",
        "outputId": "6c136258-8c3c-4d2e-8826-f478c19ead09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>prec43</th>\n",
              "      <th>prec52</th>\n",
              "      <th>prec71</th>\n",
              "      <th>prec81</th>\n",
              "      <th>prec82</th>\n",
              "      <th>prec90</th>\n",
              "      <th>prec95</th>\n",
              "      <th>elvDiff</th>\n",
              "      <th>prec42</th>\n",
              "      <th>countts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.121396</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>0.012747</td>\n",
              "      <td>0.016085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.877557</td>\n",
              "      <td>0.015478</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137568</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>0.002904</td>\n",
              "      <td>0.011978</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>0.002178</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>-1.215946</td>\n",
              "      <td>0.008348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024931</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-10.089323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156550</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.018104</td>\n",
              "      <td>0.021832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.180551</td>\n",
              "      <td>0.007455</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.207087</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.015135</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.033832</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>2.104055</td>\n",
              "      <td>0.021189</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 98 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ...    prec43    prec52  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...  0.121396  0.001517   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...  0.137568  0.001815   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...  0.024931  0.000000   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...  0.156550  0.002130   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...  0.207087  0.000890   \n",
              "\n",
              "     prec71    prec81    prec82    prec90    prec95    elvDiff    prec42  \\\n",
              "0  0.012747  0.016085  0.000000  0.028832  0.000000  12.877557  0.015478   \n",
              "1  0.002904  0.011978  0.000363  0.002178  0.000363  -1.215946  0.008348   \n",
              "2  0.005540  0.000000  0.000000  0.011080  0.000000 -10.089323  0.000000   \n",
              "3  0.018104  0.021832  0.000000  0.023429  0.000000   5.180551  0.007455   \n",
              "4  0.015135  0.018519  0.000712  0.033832  0.000712   2.104055  0.021189   \n",
              "\n",
              "   countts  \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        1  \n",
              "4        1  \n",
              "\n",
              "[5 rows x 98 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# constant features\n",
        "constant_df = df.iloc[:, :97]\n",
        "constant_df[\"countts\"] = df[\"countts\"]\n",
        "constant_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VFMIj9o62gzG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kH_xDVW2gwO",
        "outputId": "e4bfffe4-81ec-4d70-e49c-c372109637ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(815, 20)\n"
          ]
        }
      ],
      "source": [
        "# select 20 constant features based on pearson correlation value, and then get the costant adjacency matrix\n",
        "# there is only one constant matrix for all the events\n",
        "\n",
        "y = df[\"countts\"].copy()\n",
        "X_constant = df[[\"land21\", \"fuseCount\", \"landTotal\", \"ohLength\", \"poleCount\",\n",
        "        \"reclrCount\", \"land22\", \"land24\", \"land23\", \"land43\", \"latwrf\",\n",
        "        \"avgHardSDI\", \"avgHardBA\", \"soilDepth\", \"stdHardBA\", \"hydNo\",\n",
        "        \"prec81\", \"avgTPA\", \"stdHardSDI\", \"avgSDI\"\n",
        "     ]]\n",
        "\n",
        "X_constant = X_constant.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X_constant = scaler.fit_transform(X_constant)\n",
        "\n",
        "constant_reshaped_data = X_constant.reshape(290, 815, 20)\n",
        "constant_reshaped_data = constant_reshaped_data[0,:,:]\n",
        "print(constant_reshaped_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mzdlCQOZ2gtY"
      },
      "outputs": [],
      "source": [
        "def mean_cosine_similarity(arr1, arr2):\n",
        "    norm1 = np.linalg.norm(arr1)\n",
        "    norm2 = np.linalg.norm(arr2)\n",
        "    arr1 = arr1 / norm1\n",
        "    arr2 = arr2 / norm2\n",
        "    similarities = np.sum(arr1 * arr2)\n",
        "    return np.mean(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHtYEsqDEynJ"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/constant_adjacent.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     nearest_matrix[k, nearest_neighbors[k]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m constant_adjacency_matrix[(similarity_matrix \u001b[38;5;241m>\u001b[39m threshold) \u001b[38;5;241m&\u001b[39m (nearest_matrix \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/constant_adjacent.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_adjacency_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/OPM/lib/python3.8/site-packages/numpy/lib/npyio.py:518\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    517\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 518\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/constant_adjacent.npy'"
          ]
        }
      ],
      "source": [
        "n_nodes = constant_reshaped_data.shape[0]\n",
        "constant_adjacency_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "similarity_matrix = np.zeros((n_nodes, n_nodes))\n",
        "for i in range(n_nodes):\n",
        "    for j in range(i + 1, n_nodes):\n",
        "        similarity = mean_cosine_similarity(constant_reshaped_data[i], constant_reshaped_data[j])\n",
        "        similarity_matrix[i, j] = similarity\n",
        "        similarity_matrix[j, i] = similarity\n",
        "\n",
        "nearest_neighbors = np.argsort(-similarity_matrix, axis=1)[:, 1:9]   # number of neighbors, hyperparameter tuning\n",
        "\n",
        "eighth_neighbors = np.sort(similarity_matrix, axis=1)[:, -8]  # Get the 8th largest value\n",
        "average_eighth_neighbor_value = np.mean(eighth_neighbors)\n",
        "threshold = average_eighth_neighbor_value\n",
        "\n",
        "nearest_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "for k in range(n_nodes):\n",
        "    nearest_matrix[k, nearest_neighbors[k]] = 1\n",
        "constant_adjacency_matrix[(similarity_matrix > threshold) & (nearest_matrix == 1)] = 1\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/constant_adjacent.npy\", constant_adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yMTv0tbW6aMH"
      },
      "outputs": [],
      "source": [
        "constant_adjacency_matrix = np.load(\"/home/xus23004/Project/OPM/Results/constant_adjacency_matrix.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZHn7LPrEykR"
      },
      "outputs": [],
      "source": [
        "# dynamic features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylAMg0GXEyeV",
        "outputId": "996d9d04-d998-47f0-9d11-3f01a2f33f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(290, 815, 30)\n"
          ]
        }
      ],
      "source": [
        "# select 30 dynamic features based on pearson correlation value, and then get the dynamic adjacency matrix\n",
        "# each event has its own dynamic adjacency matrix\n",
        "\n",
        "X_dynamic = df[[\"binaryts\", \"coggt27\", \"ggt27\", \"ggt22\", \"coggt22\",\n",
        "        \"stdW850\", \"maxGUST\", \"peakW850\", \"maxW850\", \"peakGUST\", \"avgAFWA_CAPE\",\n",
        "        \"avgSSRUN\", \"peakAFWA_LLWS\", \"peakSSRUN\", \"coggt17\", \"maxSSRUN\", \"stdAFWA_RAIN\",\n",
        "        \"maxAFWA_CAPE\", \"stdAFWA_TOTPRECIP\", \"avgAFWA_RAIN\", \"ggt17\", \"avgAFWA_TOTPRECIP\",\n",
        "        \"stdSMOIS4\", \"stdGUST\", \"stdSSRUN\", \"stdTDIF\", \"peakPSFC\", \"minPSFC\",\n",
        "        \"peakAFWA_MSLP\", \"minAFWA_MSLP\"]]\n",
        "\n",
        "\n",
        "X_dynamic = X_dynamic.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X_dynamic = scaler.fit_transform(X_dynamic)\n",
        "\n",
        "dynamic_reshaped_data = X_dynamic.reshape(290, 815, 30)\n",
        "print(dynamic_reshaped_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u_WEduy62gqw",
        "outputId": "f7b76644-e625-4026-ddbd-7cfda5eaedad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n"
          ]
        }
      ],
      "source": [
        "n_nodes = dynamic_reshaped_data.shape[1]\n",
        "events = dynamic_reshaped_data.shape[0]\n",
        "dynamic_adjacency_matrix = np.zeros((events, n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "for event in range(events):\n",
        "    print(event)\n",
        "    similarity_matrix = np.zeros((n_nodes, n_nodes))\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(i + 1, n_nodes):\n",
        "            similarity = mean_cosine_similarity(dynamic_reshaped_data[event, i], dynamic_reshaped_data[event, j])\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity\n",
        "\n",
        "    nearest_neighbors = np.argsort(-similarity_matrix, axis=1)[:, 1:9]\n",
        "\n",
        "    eighth_neighbors = np.sort(similarity_matrix, axis=1)[:, -8]  # Get the 8th largest value\n",
        "    average_eighth_neighbor_value = np.mean(eighth_neighbors)\n",
        "    threshold = average_eighth_neighbor_value\n",
        "\n",
        "    nearest_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "    for k in range(n_nodes):\n",
        "        nearest_matrix[k, nearest_neighbors[k]] = 1\n",
        "    dynamic_adjacency_matrix[event][(similarity_matrix > threshold) & (nearest_matrix == 1)] = 1\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/dynamic_adjacent_8.npy\", dynamic_adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m-WJHRLJ6jsm"
      },
      "outputs": [],
      "source": [
        "dynamic_adjacency_matrix = np.load(\"/home/xus23004/Project/OPM/Results/dynamic_adjacency_matrix.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXK_Ag136jbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dhQTmraR2gn5"
      },
      "outputs": [],
      "source": [
        "# combine the constant and dynamic matrix, and obtain the final adjacency matrix for each event\n",
        "n_nodes = 815\n",
        "events = 290"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKhSPQajHMCt"
      },
      "outputs": [],
      "source": [
        "adjacency_matrix = np.zeros((events, n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "for event in range(events):\n",
        "    adjacency_matrix[event] = 0.3897679 * constant_adjacency_matrix + 0.6102321 * dynamic_adjacency_matrix[event]\n",
        "\n",
        "# There are different combination methods, or even modify the network to combine constant and dynamic information. Still working on this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX1SeYpX2z3v"
      },
      "outputs": [],
      "source": [
        "np.save(\"/content/drive/MyDrive/cosntantdynamicMix_adjacent_8.npy\", adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "agSkj2MR2z0X"
      },
      "outputs": [],
      "source": [
        "adjacency_matrix = np.load(\"/home/xus23004/Project/OPM/Results/cosntantdynamicMix_adjacency_matrix.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz2We-JU2zu5",
        "outputId": "bce1e810-16e2-487a-b3da-9f6e15669b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[    0.   536.   623.   741.  2653.   313.   490.  1323.   484.   815.\n",
            "  1112.   674.   205.   694.  1269.   656.   137.   460.   122.   932.\n",
            "   328.   527.   794.  3524.   582.   773.   566.  1215.   880. 16022.\n",
            "   756.   676.  1598. 15829.  1971.    65.   208.   241.   152.   163.\n",
            "   217.   107.   327.   111.   349.   153.   187.   179.   390.   652.\n",
            "   124.    79.   186.   184.   510.    85.   256.   159.   113.   196.\n",
            "    62.   113.    44.   129.   480.    69.    64.   109.   115.   278.\n",
            "   101.   302.    94.    74.    66.   134.    62.    74.   121.   110.\n",
            "    81.    68.    51.    94.    71.   780.    38.    65.    32.    57.\n",
            "    97.    50.    89.   140.   115.    79.   133.   161.   133.    92.\n",
            "   125.   132.    68.   119.    61.   127.   309.   137.   226.    60.\n",
            "   494.  4558.    89.   171.   103.   336.    74.    92.    80.   139.\n",
            "   167.    64.    75.    69.   202.    46.  2935.   180.   204.   104.\n",
            "   310.   318.   178.   404.   190.   112.   100.   421.    67.   489.\n",
            "    75.    96.   108.   128.    72.    61.    56.   187.   508.    39.\n",
            "   136.   100.    66.   374.    95.    48.    67.  1315.    52.    46.\n",
            "    78.    37.    89.    74.   147.    93.    56.    73.   109.   128.\n",
            "   102.   214.    76.   132.    80.   146.   116.   186.  2155.   133.\n",
            "    97.  2538.    99.    52.   207.    83.   118.   224.   223.    60.\n",
            "   539.    44.    44.   147.    71.    57.    39.    36.    69.   120.\n",
            "   100.  1768.   147.   114.    53.    87.    71.   107.   400. 21377.\n",
            "   313.   291.   892.   736.   141.   129.   262.   982.  1045.    98.\n",
            "  1405.   120.   948.   331.    52.  1089.   185.   169.   116.   272.\n",
            "   264.   289.    77.   209.    44.   189.   193.   248.   971.   142.\n",
            "   200.  1834.   944.   975.   165.    94.    98.  1070.   187.   643.\n",
            "   499.    96.    83.   138.   264.   228.    57.   772.   160.   373.\n",
            "   445.    43.    61.   143.   146.    37.   191.   288.    50.   101.\n",
            "    72.   316.   227.   139.   159.   185.   188.   527.    95.   839.\n",
            "   127.    82.    39.   125.  3823.    78.    70.    44.    60.    81.\n",
            "   635.]\n"
          ]
        }
      ],
      "source": [
        "# \"counts\" value for each event\n",
        "\n",
        "y = df[\"countts\"].copy()\n",
        "unique_test_groups = np.unique(group_labels)\n",
        "actual_counts = np.zeros(len(unique_test_groups)+1)\n",
        "\n",
        "for group in unique_test_groups:\n",
        "    group_actual = y[group_labels == group]\n",
        "    actual_counts[group] = np.int32(np.sum(group_actual))\n",
        "\n",
        "print(actual_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY85Rbj62zrl",
        "outputId": "2f73a44e-9809-4430-afed-107e9a5e3873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NaN, 'Group 2', 'Group 2', 'Group 2', 'Group 3', ..., 'Group 1', 'Group 1', 'Group 1', 'Group 1', 'Group 2']\n",
            "Length: 291\n",
            "Categories (4, object): ['Group 1' < 'Group 2' < 'Group 3' < 'Group 4']\n",
            "Group 1    208\n",
            "Group 2     44\n",
            "Group 3     35\n",
            "Group 4      3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# classify events into different groups based on \"counts\", this part may be not used in the following code\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "bin_edges = [0, 300, 750, 5000, float('inf')]\n",
        "bin_labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4']\n",
        "\n",
        "group_array = pd.cut(actual_counts, bins=bin_edges, labels=bin_labels)\n",
        "print(group_array)\n",
        "group_series = pd.Series(group_array)\n",
        "\n",
        "group_counts = group_series.value_counts()\n",
        "print(group_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PuGdJFof69rG"
      },
      "outputs": [],
      "source": [
        "# All selected 50 features, and obtained adjacency matrix, then do GCN\n",
        "\n",
        "\n",
        "y = df[\"countts\"].copy()\n",
        "X = df[[\"land21\", \"fuseCount\", \"landTotal\", \"ohLength\", \"poleCount\",\n",
        "        \"reclrCount\", \"land22\", \"land24\", \"land23\", \"land43\", \"latwrf\",\n",
        "        \"avgHardSDI\", \"avgHardBA\", \"soilDepth\", \"stdHardBA\", \"hydNo\",\n",
        "        \"prec81\", \"avgTPA\", \"stdHardSDI\", \"avgSDI\", \"binaryts\", \"coggt27\", \"ggt27\", \"ggt22\", \"coggt22\",\n",
        "        \"stdW850\", \"maxGUST\", \"peakW850\", \"maxW850\", \"peakGUST\", \"avgAFWA_CAPE\",\n",
        "        \"avgSSRUN\", \"peakAFWA_LLWS\", \"peakSSRUN\", \"coggt17\", \"maxSSRUN\", \"stdAFWA_RAIN\",\n",
        "        \"maxAFWA_CAPE\", \"stdAFWA_TOTPRECIP\", \"avgAFWA_RAIN\", \"ggt17\", \"avgAFWA_TOTPRECIP\",\n",
        "        \"stdSMOIS4\", \"stdGUST\", \"stdSSRUN\", \"stdTDIF\", \"peakPSFC\", \"minPSFC\",\n",
        "        \"peakAFWA_MSLP\", \"minAFWA_MSLP\"]]\n",
        "\n",
        "\n",
        "X = X.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OEJYw497h8L"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GCNForecast(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNForecast, self).__init__()\n",
        "        self.conv1_static = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv1_dynamic = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2_static = GCNConv(hidden_channels, out_channels)\n",
        "        self.conv2_dynamic = GCNConv(hidden_channels, out_channels)\n",
        "        self.fc1 = nn.Linear(2*out_channels, 16)\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x, edge_index_static, edge_index_dynamic):\n",
        "        batch_size, num_nodes, _ = x.size()\n",
        "        x = x.view(batch_size * num_nodes, -1)  # Reshape to (batch_size * num_nodes, in_channels)\n",
        "        x_static = self.conv1_static(x, edge_index_static)\n",
        "        x_dynamic = self.conv1_dynamic(x, edge_index_dynamic)\n",
        "\n",
        "        x_static = F.relu(x_static)\n",
        "        x_dynamic = F.relu(x_dynamic)\n",
        "\n",
        "        x_static = F.dropout(x_static, training=self.training)\n",
        "        x_dynamic = F.dropout(x_dynamic, training=self.training)\n",
        "\n",
        "        x_static = self.conv2_static(x_static, edge_index_static)\n",
        "        x_dynamic = self.conv2_dynamic(x_dynamic, edge_index_dynamic)\n",
        "\n",
        "        x_static = F.relu(x_static)\n",
        "        x_dynamic = F.relu(x_dynamic)\n",
        "\n",
        "        x = torch.cat((x_static, x_dynamic), dim=1)\n",
        "\n",
        "        embedding = x\n",
        "\n",
        "        x = x.view(batch_size, num_nodes, -1)  # Reshape back to (batch_size, num_nodes, out_channels)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x, embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TR2b4a27h5U"
      },
      "outputs": [],
      "source": [
        "def load_data(feature_matrix, labels):\n",
        "    # edge_index = torch.nonzero(adj_matrix).t().contiguous()\n",
        "    x = torch.tensor(feature_matrix, dtype=torch.float)\n",
        "    # y = torch.tensor(labels, dtype=torch.float).view(-1, 815, 1)  # Reshape labels to (batch_size, num_nodes, 1)\n",
        "    y = torch.tensor(labels, dtype=torch.float)    # Reshape labels to (batch_size, num_nodes, 1)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def train(model, x, edge_index_static, edge_index_dynamic, y, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out,_ = model(x, edge_index_static, edge_index_dynamic)\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def test(model, x, edge_index_static, edge_index_dynamic, y, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out,embedding = model(x, edge_index_static, edge_index_dynamic)\n",
        "      print(out.shape)\n",
        "      loss = criterion(out, y)\n",
        "    return loss.item(), out.detach().numpy().reshape(-1), embedding.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgnzWn_C7h1v",
        "outputId": "44d53f3c-f6c3-45de-87bd-55858e00261c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1:\n",
            "Test Index: 235535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:999: UserWarning: Using a target size (torch.Size([815, 1])) that is different to the input size (torch.Size([1, 815, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1577\n",
            "Fold 2:\n",
            "Test Index: 58680\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0254\n",
            "Fold 3:\n",
            "Test Index: 74980\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0397\n",
            "Fold 4:\n",
            "Test Index: 75795\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0619\n",
            "Fold 5:\n",
            "Test Index: 76610\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0218\n",
            "Fold 6:\n",
            "Test Index: 77425\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0320\n",
            "Fold 7:\n",
            "Test Index: 78240\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0401\n",
            "Fold 8:\n",
            "Test Index: 79055\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0316\n",
            "Fold 9:\n",
            "Test Index: 79870\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0203\n",
            "Fold 10:\n",
            "Test Index: 80685\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0323\n",
            "Fold 11:\n",
            "Test Index: 81500\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0321\n",
            "Fold 12:\n",
            "Test Index: 82315\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0158\n",
            "Fold 13:\n",
            "Test Index: 83130\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0305\n",
            "Fold 14:\n",
            "Test Index: 83945\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0265\n",
            "Fold 15:\n",
            "Test Index: 84760\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0370\n",
            "Fold 16:\n",
            "Test Index: 85575\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0787\n",
            "Fold 17:\n",
            "Test Index: 86390\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0313\n",
            "Fold 18:\n",
            "Test Index: 74165\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0328\n",
            "Fold 19:\n",
            "Test Index: 73350\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0159\n",
            "Fold 20:\n",
            "Test Index: 72535\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0266\n",
            "Fold 21:\n",
            "Test Index: 65200\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0218\n",
            "Fold 22:\n",
            "Test Index: 60310\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0381\n",
            "Fold 23:\n",
            "Test Index: 61125\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0310\n",
            "Fold 24:\n",
            "Test Index: 61940\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0215\n",
            "Fold 25:\n",
            "Test Index: 62755\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0371\n",
            "Fold 26:\n",
            "Test Index: 63570\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0575\n",
            "Fold 27:\n",
            "Test Index: 64385\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0233\n",
            "Fold 28:\n",
            "Test Index: 66015\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0218\n",
            "Fold 29:\n",
            "Test Index: 71720\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0161\n",
            "Fold 30:\n",
            "Test Index: 66830\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0281\n",
            "Fold 31:\n",
            "Test Index: 67645\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0280\n",
            "Fold 32:\n",
            "Test Index: 68460\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1884\n",
            "Fold 33:\n",
            "Test Index: 69275\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0327\n",
            "Fold 34:\n",
            "Test Index: 70090\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0245\n",
            "Fold 35:\n",
            "Test Index: 70905\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0280\n",
            "Fold 36:\n",
            "Test Index: 87205\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0599\n",
            "Fold 37:\n",
            "Test Index: 88020\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0257\n",
            "Fold 38:\n",
            "Test Index: 88835\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1073\n",
            "Fold 39:\n",
            "Test Index: 110025\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0297\n",
            "Fold 40:\n",
            "Test Index: 105135\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0826\n",
            "Fold 41:\n",
            "Test Index: 105950\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0907\n",
            "Fold 42:\n",
            "Test Index: 106765\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0432\n",
            "Fold 43:\n",
            "Test Index: 107580\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0885\n",
            "Fold 44:\n",
            "Test Index: 108395\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0445\n",
            "Fold 45:\n",
            "Test Index: 109210\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0259\n",
            "Fold 46:\n",
            "Test Index: 110840\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0992\n",
            "Fold 47:\n",
            "Test Index: 103505\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0959\n",
            "Fold 48:\n",
            "Test Index: 111655\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0227\n",
            "Fold 49:\n",
            "Test Index: 112470\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1127\n",
            "Fold 50:\n",
            "Test Index: 113285\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0351\n",
            "Fold 51:\n",
            "Test Index: 114100\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0330\n",
            "Fold 52:\n",
            "Test Index: 114915\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0308\n",
            "Fold 53:\n",
            "Test Index: 115730\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0513\n",
            "Fold 54:\n",
            "Test Index: 104320\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0390\n",
            "Fold 55:\n",
            "Test Index: 102690\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0476\n",
            "Fold 56:\n",
            "Test Index: 89650\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 1.2304\n",
            "Fold 57:\n",
            "Test Index: 95355\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0383\n",
            "Fold 58:\n",
            "Test Index: 90465\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0245\n",
            "Fold 59:\n",
            "Test Index: 91280\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0431\n",
            "Fold 60:\n",
            "Test Index: 92095\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0271\n",
            "Fold 61:\n",
            "Test Index: 92910\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0782\n",
            "Fold 62:\n",
            "Test Index: 93725\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0186\n",
            "Fold 63:\n",
            "Test Index: 94540\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0310\n",
            "Fold 64:\n",
            "Test Index: 96170\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0477\n",
            "Fold 65:\n",
            "Test Index: 101875\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.7497\n",
            "Fold 66:\n",
            "Test Index: 96985\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0493\n",
            "Fold 67:\n",
            "Test Index: 97800\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0318\n",
            "Fold 68:\n",
            "Test Index: 98615\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0289\n",
            "Fold 69:\n",
            "Test Index: 99430\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0329\n",
            "Fold 70:\n",
            "Test Index: 100245\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0517\n",
            "Fold 71:\n",
            "Test Index: 101060\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0256\n",
            "Fold 72:\n",
            "Test Index: 59495\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0247\n",
            "Fold 73:\n",
            "Test Index: 57865\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0241\n",
            "Fold 74:\n",
            "Test Index: 234720\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0695\n",
            "Fold 75:\n",
            "Test Index: 57050\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0507\n",
            "Fold 76:\n",
            "Test Index: 15485\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1193\n",
            "Fold 77:\n",
            "Test Index: 16300\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1186\n",
            "Fold 78:\n",
            "Test Index: 17115\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1801\n",
            "Fold 79:\n",
            "Test Index: 17930\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.9985\n",
            "Fold 80:\n",
            "Test Index: 18745\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1391\n",
            "Fold 81:\n",
            "Test Index: 19560\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1702\n",
            "Fold 82:\n",
            "Test Index: 20375\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1256\n",
            "Fold 83:\n",
            "Test Index: 21190\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3282\n",
            "Fold 84:\n",
            "Test Index: 22005\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1826\n",
            "Fold 85:\n",
            "Test Index: 22820\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 4.6000\n",
            "Fold 86:\n",
            "Test Index: 23635\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1794\n",
            "Fold 87:\n",
            "Test Index: 24450\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1389\n",
            "Fold 88:\n",
            "Test Index: 25265\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3922\n",
            "Fold 89:\n",
            "Test Index: 26080\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 4.6524\n",
            "Fold 90:\n",
            "Test Index: 26895\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.4837\n",
            "Fold 91:\n",
            "Test Index: 14670\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2007\n",
            "Fold 92:\n",
            "Test Index: 13855\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0423\n",
            "Fold 93:\n",
            "Test Index: 13040\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1013\n",
            "Fold 94:\n",
            "Test Index: 5705\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1051\n",
            "Fold 95:\n",
            "Test Index: 815\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1308\n",
            "Fold 96:\n",
            "Test Index: 1630\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1872\n",
            "Fold 97:\n",
            "Test Index: 2445\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.7387\n",
            "Fold 98:\n",
            "Test Index: 3260\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0788\n",
            "Fold 99:\n",
            "Test Index: 4075\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1238\n",
            "Fold 100:\n",
            "Test Index: 4890\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3375\n",
            "Fold 101:\n",
            "Test Index: 6520\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1659\n",
            "Fold 102:\n",
            "Test Index: 12225\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1448\n",
            "Fold 103:\n",
            "Test Index: 7335\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2990\n",
            "Fold 104:\n",
            "Test Index: 8150\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1484\n",
            "Fold 105:\n",
            "Test Index: 8965\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0753\n",
            "Fold 106:\n",
            "Test Index: 9780\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2021\n",
            "Fold 107:\n",
            "Test Index: 10595\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2981\n",
            "Fold 108:\n",
            "Test Index: 11410\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2095\n",
            "Fold 109:\n",
            "Test Index: 27710\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0275\n",
            "Fold 110:\n",
            "Test Index: 28525\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0609\n",
            "Fold 111:\n",
            "Test Index: 29340\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0643\n",
            "Fold 112:\n",
            "Test Index: 50530\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0377\n",
            "Fold 113:\n",
            "Test Index: 45640\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0402\n",
            "Fold 114:\n",
            "Test Index: 46455\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0366\n",
            "Fold 115:\n",
            "Test Index: 47270\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0564\n",
            "Fold 116:\n",
            "Test Index: 48085\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0276\n",
            "Fold 117:\n",
            "Test Index: 48900\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0302\n",
            "Fold 118:\n",
            "Test Index: 49715\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0188\n",
            "Fold 119:\n",
            "Test Index: 51345\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1215\n",
            "Fold 120:\n",
            "Test Index: 44010\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0226\n",
            "Fold 121:\n",
            "Test Index: 52160\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0538\n",
            "Fold 122:\n",
            "Test Index: 52975\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0278\n",
            "Fold 123:\n",
            "Test Index: 53790\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0351\n",
            "Fold 124:\n",
            "Test Index: 54605\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0380\n",
            "Fold 125:\n",
            "Test Index: 55420\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0807\n",
            "Fold 126:\n",
            "Test Index: 56235\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0672\n",
            "Fold 127:\n",
            "Test Index: 44825\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0655\n",
            "Fold 128:\n",
            "Test Index: 43195\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1206\n",
            "Fold 129:\n",
            "Test Index: 30155\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0570\n",
            "Fold 130:\n",
            "Test Index: 35860\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0473\n",
            "Fold 131:\n",
            "Test Index: 30970\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0616\n",
            "Fold 132:\n",
            "Test Index: 31785\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0885\n",
            "Fold 133:\n",
            "Test Index: 32600\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0342\n",
            "Fold 134:\n",
            "Test Index: 33415\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1088\n",
            "Fold 135:\n",
            "Test Index: 34230\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0359\n",
            "Fold 136:\n",
            "Test Index: 35045\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0912\n",
            "Fold 137:\n",
            "Test Index: 36675\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0419\n",
            "Fold 138:\n",
            "Test Index: 42380\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0450\n",
            "Fold 139:\n",
            "Test Index: 37490\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0608\n",
            "Fold 140:\n",
            "Test Index: 38305\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0869\n",
            "Fold 141:\n",
            "Test Index: 39120\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1510\n",
            "Fold 142:\n",
            "Test Index: 39935\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0359\n",
            "Fold 143:\n",
            "Test Index: 40750\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0229\n",
            "Fold 144:\n",
            "Test Index: 41565\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0505\n",
            "Fold 145:\n",
            "Test Index: 116545\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0507\n",
            "Fold 146:\n",
            "Test Index: 117360\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0421\n",
            "Fold 147:\n",
            "Test Index: 118175\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0255\n",
            "Fold 148:\n",
            "Test Index: 118990\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0495\n",
            "Fold 149:\n",
            "Test Index: 193155\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2115\n",
            "Fold 150:\n",
            "Test Index: 193970\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0388\n",
            "Fold 151:\n",
            "Test Index: 194785\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0568\n",
            "Fold 152:\n",
            "Test Index: 195600\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.4351\n",
            "Fold 153:\n",
            "Test Index: 196415\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2168\n",
            "Fold 154:\n",
            "Test Index: 197230\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2281\n",
            "Fold 155:\n",
            "Test Index: 198045\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0504\n",
            "Fold 156:\n",
            "Test Index: 198860\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0252\n",
            "Fold 157:\n",
            "Test Index: 199675\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0310\n",
            "Fold 158:\n",
            "Test Index: 200490\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2238\n",
            "Fold 159:\n",
            "Test Index: 201305\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0516\n",
            "Fold 160:\n",
            "Test Index: 202120\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1560\n",
            "Fold 161:\n",
            "Test Index: 202935\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1184\n",
            "Fold 162:\n",
            "Test Index: 203750\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0277\n",
            "Fold 163:\n",
            "Test Index: 204565\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0367\n",
            "Fold 164:\n",
            "Test Index: 192340\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1857\n",
            "Fold 165:\n",
            "Test Index: 191525\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0440\n",
            "Fold 166:\n",
            "Test Index: 190710\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0477\n",
            "Fold 167:\n",
            "Test Index: 183375\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0515\n",
            "Fold 168:\n",
            "Test Index: 178485\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3770\n",
            "Fold 169:\n",
            "Test Index: 179300\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0405\n",
            "Fold 170:\n",
            "Test Index: 180115\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2217\n",
            "Fold 171:\n",
            "Test Index: 180930\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0937\n",
            "Fold 172:\n",
            "Test Index: 181745\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0442\n",
            "Fold 173:\n",
            "Test Index: 182560\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2226\n",
            "Fold 174:\n",
            "Test Index: 184190\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0551\n",
            "Fold 175:\n",
            "Test Index: 189895\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0145\n",
            "Fold 176:\n",
            "Test Index: 185005\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0477\n",
            "Fold 177:\n",
            "Test Index: 185820\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0642\n",
            "Fold 178:\n",
            "Test Index: 186635\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0848\n",
            "Fold 179:\n",
            "Test Index: 187450\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0797\n",
            "Fold 180:\n",
            "Test Index: 188265\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0411\n",
            "Fold 181:\n",
            "Test Index: 189080\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0708\n",
            "Fold 182:\n",
            "Test Index: 205380\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0399\n",
            "Fold 183:\n",
            "Test Index: 206195\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0684\n",
            "Fold 184:\n",
            "Test Index: 207010\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0606\n",
            "Fold 185:\n",
            "Test Index: 228200\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0342\n",
            "Fold 186:\n",
            "Test Index: 223310\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0395\n",
            "Fold 187:\n",
            "Test Index: 224125\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0538\n",
            "Fold 188:\n",
            "Test Index: 224940\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1269\n",
            "Fold 189:\n",
            "Test Index: 225755\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0338\n",
            "Fold 190:\n",
            "Test Index: 226570\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2127\n",
            "Fold 191:\n",
            "Test Index: 227385\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0486\n",
            "Fold 192:\n",
            "Test Index: 229015\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0623\n",
            "Fold 193:\n",
            "Test Index: 221680\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0359\n",
            "Fold 194:\n",
            "Test Index: 229830\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0654\n",
            "Fold 195:\n",
            "Test Index: 230645\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.9821\n",
            "Fold 196:\n",
            "Test Index: 231460\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0369\n",
            "Fold 197:\n",
            "Test Index: 232275\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0690\n",
            "Fold 198:\n",
            "Test Index: 233090\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0138\n",
            "Fold 199:\n",
            "Test Index: 233905\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0261\n",
            "Fold 200:\n",
            "Test Index: 222495\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0398\n",
            "Fold 201:\n",
            "Test Index: 220865\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0641\n",
            "Fold 202:\n",
            "Test Index: 207825\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0196\n",
            "Fold 203:\n",
            "Test Index: 213530\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0537\n",
            "Fold 204:\n",
            "Test Index: 208640\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2030\n",
            "Fold 205:\n",
            "Test Index: 209455\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0658\n",
            "Fold 206:\n",
            "Test Index: 210270\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0932\n",
            "Fold 207:\n",
            "Test Index: 211085\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1226\n",
            "Fold 208:\n",
            "Test Index: 211900\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0194\n",
            "Fold 209:\n",
            "Test Index: 212715\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0266\n",
            "Fold 210:\n",
            "Test Index: 214345\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0558\n",
            "Fold 211:\n",
            "Test Index: 220050\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0890\n",
            "Fold 212:\n",
            "Test Index: 215160\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0368\n",
            "Fold 213:\n",
            "Test Index: 215975\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0512\n",
            "Fold 214:\n",
            "Test Index: 216790\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0918\n",
            "Fold 215:\n",
            "Test Index: 217605\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0335\n",
            "Fold 216:\n",
            "Test Index: 218420\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0362\n",
            "Fold 217:\n",
            "Test Index: 219235\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0179\n",
            "Fold 218:\n",
            "Test Index: 177670\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0327\n",
            "Fold 219:\n",
            "Test Index: 176855\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2483\n",
            "Fold 220:\n",
            "Test Index: 176040\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2375\n",
            "Fold 221:\n",
            "Test Index: 139365\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0212\n",
            "Fold 222:\n",
            "Test Index: 134475\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0168\n",
            "Fold 223:\n",
            "Test Index: 135290\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0268\n",
            "Fold 224:\n",
            "Test Index: 136105\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0301\n",
            "Fold 225:\n",
            "Test Index: 136920\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0301\n",
            "Fold 226:\n",
            "Test Index: 137735\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0329\n",
            "Fold 227:\n",
            "Test Index: 138550\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0548\n",
            "Fold 228:\n",
            "Test Index: 140180\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0620\n",
            "Fold 229:\n",
            "Test Index: 132845\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0746\n",
            "Fold 230:\n",
            "Test Index: 140995\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0236\n",
            "Fold 231:\n",
            "Test Index: 141810\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0397\n",
            "Fold 232:\n",
            "Test Index: 142625\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0331\n",
            "Fold 233:\n",
            "Test Index: 143440\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0718\n",
            "Fold 234:\n",
            "Test Index: 144255\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.5499\n",
            "Fold 235:\n",
            "Test Index: 145070\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0281\n",
            "Fold 236:\n",
            "Test Index: 133660\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0376\n",
            "Fold 237:\n",
            "Test Index: 132030\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0515\n",
            "Fold 238:\n",
            "Test Index: 146700\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.6486\n",
            "Fold 239:\n",
            "Test Index: 124695\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0431\n",
            "Fold 240:\n",
            "Test Index: 119805\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1034\n",
            "Fold 241:\n",
            "Test Index: 120620\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0446\n",
            "Fold 242:\n",
            "Test Index: 121435\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0609\n",
            "Fold 243:\n",
            "Test Index: 122250\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0406\n",
            "Fold 244:\n",
            "Test Index: 123065\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0262\n",
            "Fold 245:\n",
            "Test Index: 123880\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1524\n",
            "Fold 246:\n",
            "Test Index: 125510\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0238\n",
            "Fold 247:\n",
            "Test Index: 131215\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0461\n",
            "Fold 248:\n",
            "Test Index: 126325\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0180\n",
            "Fold 249:\n",
            "Test Index: 127140\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3169\n",
            "Fold 250:\n",
            "Test Index: 127955\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0152\n",
            "Fold 251:\n",
            "Test Index: 128770\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0200\n",
            "Fold 252:\n",
            "Test Index: 129585\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0369\n",
            "Fold 253:\n",
            "Test Index: 130400\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0404\n",
            "Fold 254:\n",
            "Test Index: 145885\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0397\n",
            "Fold 255:\n",
            "Test Index: 147515\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0303\n",
            "Fold 256:\n",
            "Test Index: 175225\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0660\n",
            "Fold 257:\n",
            "Test Index: 168705\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0924\n",
            "Fold 258:\n",
            "Test Index: 163815\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0478\n",
            "Fold 259:\n",
            "Test Index: 164630\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0357\n",
            "Fold 260:\n",
            "Test Index: 165445\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0218\n",
            "Fold 261:\n",
            "Test Index: 166260\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0265\n",
            "Fold 262:\n",
            "Test Index: 167075\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0540\n",
            "Fold 263:\n",
            "Test Index: 167890\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0298\n",
            "Fold 264:\n",
            "Test Index: 169520\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 6.3971\n",
            "Fold 265:\n",
            "Test Index: 162185\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0259\n",
            "Fold 266:\n",
            "Test Index: 170335\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0812\n",
            "Fold 267:\n",
            "Test Index: 171150\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0803\n",
            "Fold 268:\n",
            "Test Index: 171965\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.2068\n",
            "Fold 269:\n",
            "Test Index: 172780\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1859\n",
            "Fold 270:\n",
            "Test Index: 173595\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0358\n",
            "Fold 271:\n",
            "Test Index: 174410\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0443\n",
            "Fold 272:\n",
            "Test Index: 163000\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.3739\n",
            "Fold 273:\n",
            "Test Index: 161370\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0413\n",
            "Fold 274:\n",
            "Test Index: 148330\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0194\n",
            "Fold 275:\n",
            "Test Index: 154035\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1441\n",
            "Fold 276:\n",
            "Test Index: 149145\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0607\n",
            "Fold 277:\n",
            "Test Index: 149960\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0843\n",
            "Fold 278:\n",
            "Test Index: 150775\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0540\n",
            "Fold 279:\n",
            "Test Index: 151590\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0738\n",
            "Fold 280:\n",
            "Test Index: 152405\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0541\n",
            "Fold 281:\n",
            "Test Index: 153220\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0343\n",
            "Fold 282:\n",
            "Test Index: 154850\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0451\n",
            "Fold 283:\n",
            "Test Index: 160555\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0458\n",
            "Fold 284:\n",
            "Test Index: 155665\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0179\n",
            "Fold 285:\n",
            "Test Index: 156480\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0425\n",
            "Fold 286:\n",
            "Test Index: 157295\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0370\n",
            "Fold 287:\n",
            "Test Index: 158110\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0171\n",
            "Fold 288:\n",
            "Test Index: 158925\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0274\n",
            "Fold 289:\n",
            "Test Index: 159740\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.0512\n",
            "Fold 290:\n",
            "Test Index: 0\n",
            "torch.Size([1, 815, 1])\n",
            "Test Loss: 0.1194\n"
          ]
        }
      ],
      "source": [
        "# do leave one out based on events\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float)\n",
        "constant_adjacency_matrix = torch.tensor(constant_adjacency_matrix, dtype=torch.float)\n",
        "dynamic_adjacency_matrix = torch.tensor(dynamic_adjacency_matrix, dtype=torch.float)\n",
        "\n",
        "edge_index_static = torch.nonzero(constant_adjacency_matrix).t().contiguous()\n",
        "\n",
        "\n",
        "feature_matrix = X            # feature matrix (290x815 , 50)\n",
        "labels = y                    # node labels for forecasting (290x815, )\n",
        "x, y = load_data(feature_matrix, labels)\n",
        "\n",
        "\n",
        "gkf = GroupKFold(n_splits=290)\n",
        "predictions = np.zeros(len(df))\n",
        "embeddings = np.zeros((len(df), 16))\n",
        "\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(gkf.split(df, groups=df[\"groupLabel\"])):\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"Test Index: {test_index[0]}\")\n",
        "\n",
        "    train_x, test_x = x[train_index].view(-1, 815, 50), x[test_index].view(-1, 815, 50)\n",
        "    train_y, test_y = y[train_index].view(-1, 815, 1), y[test_index].view(-1, 815, 1)\n",
        "\n",
        "    idx_train = train_index.reshape(-1,815)  # (289, 815)\n",
        "    idx_test = test_index.reshape(-1,815)    # (1, 815)\n",
        "\n",
        "    model = GCNForecast(in_channels=50, hidden_channels=32, out_channels=16)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    criterion = nn.HuberLoss(delta=0.25)  # Use Huber loss with delta=0.22, hyperpameter tuning\n",
        "\n",
        "    for epoch in range(10):\n",
        "        loss_total = 0.0\n",
        "\n",
        "        for event in range(289):\n",
        "            idx_start = idx_train[event][0]\n",
        "            idx_event = idx_start // 815\n",
        "\n",
        "            edge_index_dynamic = torch.nonzero(dynamic_adjacency_matrix[idx_event]).t().contiguous()\n",
        "\n",
        "            loss = train(model, train_x[event, :, :].view(1, 815, 50), edge_index_static, edge_index_dynamic, train_y[event, :, :], optimizer, criterion)\n",
        "            loss_total += loss\n",
        "        # print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}\")\n",
        "\n",
        "    #print(\"test_x size:\", test_x.shape)\n",
        "    #print(\"test_y size:\", test_y.shape)\n",
        "\n",
        "    test_event = idx_test[0][0] // 815\n",
        "    edge_index_dynamic_test = torch.nonzero(dynamic_adjacency_matrix[test_event]).t().contiguous()\n",
        "    test_loss, out, embedding = test(model, test_x, edge_index_static, edge_index_dynamic_test, test_y, criterion)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    predictions[test_index] = out\n",
        "    # embeddings[test_index] = embedding\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/predictions_GCN_HuberLoss02_nei8_15consAndDyAdj.npy\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ0D9CRy5CVp"
      },
      "outputs": [],
      "source": [
        "# evaluate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJbsS-cS69oP"
      },
      "outputs": [],
      "source": [
        "def mape(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2hkKmRLNuJW",
        "outputId": "47d30f65-eafd-4e11-d34a-698d27480039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Predicted   Actual\n",
            "1        378.0    536.0\n",
            "2        229.0    623.0\n",
            "3        187.0    741.0\n",
            "4        182.0   2653.0\n",
            "5        357.0    313.0\n",
            "6        188.0    490.0\n",
            "7        350.0   1323.0\n",
            "8        194.0    484.0\n",
            "9        444.0    815.0\n",
            "10       710.0   1112.0\n",
            "11       317.0    674.0\n",
            "12       246.0    205.0\n",
            "13       771.0    694.0\n",
            "14       255.0   1269.0\n",
            "15       306.0    656.0\n",
            "16       649.0    137.0\n",
            "17       205.0    460.0\n",
            "18       225.0    122.0\n",
            "19       265.0    932.0\n",
            "20       520.0    328.0\n",
            "21       406.0    527.0\n",
            "22       515.0    794.0\n",
            "23       503.0   3524.0\n",
            "24       119.0    582.0\n",
            "25       285.0    773.0\n",
            "26       336.0    566.0\n",
            "27      1287.0   1215.0\n",
            "28       340.0    880.0\n",
            "29       986.0  16022.0\n",
            "30       254.0    756.0\n",
            "31       285.0    676.0\n",
            "32       333.0   1598.0\n",
            "33       586.0  15829.0\n",
            "34       398.0   1971.0\n",
            "35        62.0     65.0\n",
            "36       144.0    208.0\n",
            "37       262.0    241.0\n",
            "38       268.0    152.0\n",
            "39       220.0    163.0\n",
            "40       356.0    217.0\n",
            "41       150.0    107.0\n",
            "42       389.0    327.0\n",
            "43       -15.0    111.0\n",
            "44       298.0    349.0\n",
            "45       128.0    153.0\n",
            "46       156.0    187.0\n",
            "47       -11.0    179.0\n",
            "48       172.0    390.0\n",
            "49       230.0    652.0\n",
            "50        62.0    124.0\n",
            "51        -5.0     79.0\n",
            "52       192.0    186.0\n",
            "53        39.0    184.0\n",
            "54       348.0    510.0\n",
            "55        24.0     85.0\n",
            "56       155.0    256.0\n",
            "57        -1.0    159.0\n",
            "58       135.0    113.0\n",
            "59       209.0    196.0\n",
            "60        74.0     62.0\n",
            "61        62.0    113.0\n",
            "62        85.0     44.0\n",
            "63       137.0    129.0\n",
            "64       404.0    480.0\n",
            "65       293.0     69.0\n",
            "66       115.0     64.0\n",
            "67        89.0    109.0\n",
            "68        13.0    115.0\n",
            "69       301.0    278.0\n",
            "70       294.0    101.0\n",
            "71       142.0    302.0\n",
            "72        82.0     94.0\n",
            "73        60.0     74.0\n",
            "74       -70.0     66.0\n",
            "75       -15.0    134.0\n",
            "76       157.0     62.0\n",
            "77       -31.0     74.0\n",
            "78       -50.0    121.0\n",
            "79       289.0    110.0\n",
            "80        65.0     81.0\n",
            "81       -10.0     68.0\n",
            "82        45.0     51.0\n",
            "83        58.0     94.0\n",
            "84       140.0     71.0\n",
            "85       255.0    780.0\n",
            "86       177.0     38.0\n",
            "87       101.0     65.0\n",
            "88       141.0     32.0\n",
            "89        44.0     57.0\n",
            "90        21.0     97.0\n",
            "91        14.0     50.0\n",
            "92        86.0     89.0\n",
            "93        25.0    140.0\n",
            "94       266.0    115.0\n",
            "95        59.0     79.0\n",
            "96        48.0    133.0\n",
            "97        47.0    161.0\n",
            "98       140.0    133.0\n",
            "99        79.0     92.0\n",
            "100       48.0    125.0\n",
            "101      103.0    132.0\n",
            "102       11.0     68.0\n",
            "103      146.0    119.0\n",
            "104      127.0     61.0\n",
            "105       -8.0    127.0\n",
            "106      160.0    309.0\n",
            "107      111.0    137.0\n",
            "108       62.0    226.0\n",
            "109      106.0     60.0\n",
            "110      224.0    494.0\n",
            "111      480.0   4558.0\n",
            "112       39.0     89.0\n",
            "113       92.0    171.0\n",
            "114       63.0    103.0\n",
            "115      165.0    336.0\n",
            "116       39.0     74.0\n",
            "117      120.0     92.0\n",
            "118      -19.0     80.0\n",
            "119      218.0    139.0\n",
            "120      210.0    167.0\n",
            "121      110.0     64.0\n",
            "122      114.0     75.0\n",
            "123      138.0     69.0\n",
            "124      -36.0    202.0\n",
            "125       79.0     46.0\n",
            "126      536.0   2935.0\n",
            "127      130.0    180.0\n",
            "128      401.0    204.0\n",
            "129      100.0    104.0\n",
            "130      326.0    310.0\n",
            "131      259.0    318.0\n",
            "132      202.0    178.0\n",
            "133      114.0    404.0\n",
            "134      130.0    190.0\n",
            "135       65.0    112.0\n",
            "136       92.0    100.0\n",
            "137      335.0    421.0\n",
            "138       90.0     67.0\n",
            "139      206.0    489.0\n",
            "140      126.0     75.0\n",
            "141      128.0     96.0\n",
            "142      151.0    108.0\n",
            "143      220.0    128.0\n",
            "144      243.0     72.0\n",
            "145       66.0     61.0\n",
            "146      -10.0     56.0\n",
            "147       61.0    187.0\n",
            "148      312.0    508.0\n",
            "149      214.0     39.0\n",
            "150      333.0    136.0\n",
            "151      154.0    100.0\n",
            "152      -21.0     66.0\n",
            "153      699.0    374.0\n",
            "154      212.0     95.0\n",
            "155       89.0     48.0\n",
            "156       31.0     67.0\n",
            "157      297.0   1315.0\n",
            "158       46.0     52.0\n",
            "159       46.0     46.0\n",
            "160      204.0     78.0\n",
            "161      219.0     37.0\n",
            "162      164.0     89.0\n",
            "163      242.0     74.0\n",
            "164      342.0    147.0\n",
            "165      223.0     93.0\n",
            "166       -8.0     56.0\n",
            "167      125.0     73.0\n",
            "168       81.0    109.0\n",
            "169       68.0    128.0\n",
            "170       31.0    102.0\n",
            "171      189.0    214.0\n",
            "172       12.0     76.0\n",
            "173     -131.0    132.0\n",
            "174       17.0     80.0\n",
            "175       49.0    146.0\n",
            "176       90.0    116.0\n",
            "177      287.0    186.0\n",
            "178      447.0   2155.0\n",
            "179      101.0    133.0\n",
            "180      186.0     97.0\n",
            "181      402.0   2538.0\n",
            "182      -67.0     99.0\n",
            "183       66.0     52.0\n",
            "184      235.0    207.0\n",
            "185      397.0     83.0\n",
            "186      231.0    118.0\n",
            "187      238.0    224.0\n",
            "188       28.0    223.0\n",
            "189      179.0     60.0\n",
            "190      268.0    539.0\n",
            "191      227.0     44.0\n",
            "192       51.0     44.0\n",
            "193      143.0    147.0\n",
            "194      193.0     71.0\n",
            "195       86.0     57.0\n",
            "196       38.0     39.0\n",
            "197      171.0     36.0\n",
            "198      247.0     69.0\n",
            "199       54.0    120.0\n",
            "200       85.0    100.0\n",
            "201      767.0   1768.0\n",
            "202       72.0    147.0\n",
            "203      156.0    114.0\n",
            "204      -10.0     53.0\n",
            "205       81.0     87.0\n",
            "206      236.0     71.0\n",
            "207      137.0    107.0\n",
            "208      211.0    400.0\n",
            "209      429.0  21377.0\n",
            "210       -6.0    313.0\n",
            "211      123.0    291.0\n",
            "212      238.0    892.0\n",
            "213      131.0    736.0\n",
            "214       47.0    141.0\n",
            "215      195.0    129.0\n",
            "216      159.0    262.0\n",
            "217      183.0    982.0\n",
            "218      231.0   1045.0\n",
            "219      201.0     98.0\n",
            "220      161.0   1405.0\n",
            "221      199.0    120.0\n",
            "222      358.0    948.0\n",
            "223      233.0    331.0\n",
            "224      221.0     52.0\n",
            "225      450.0   1089.0\n",
            "226       83.0    185.0\n",
            "227      186.0    169.0\n",
            "228      213.0    116.0\n",
            "229       53.0    272.0\n",
            "230      244.0    264.0\n",
            "231      348.0    289.0\n",
            "232      199.0     77.0\n",
            "233      129.0    209.0\n",
            "234       12.0     44.0\n",
            "235      186.0    189.0\n",
            "236      114.0    193.0\n",
            "237     -458.0    248.0\n",
            "238      605.0    971.0\n",
            "239       75.0    142.0\n",
            "240       -1.0    200.0\n",
            "241      479.0   1834.0\n",
            "242      335.0    944.0\n",
            "243      364.0    975.0\n",
            "244      169.0    165.0\n",
            "245       59.0     94.0\n",
            "246       93.0     98.0\n",
            "247      388.0   1070.0\n",
            "248      160.0    187.0\n",
            "249      475.0    643.0\n",
            "250       85.0    499.0\n",
            "251       90.0     96.0\n",
            "252      167.0     83.0\n",
            "253       71.0    138.0\n",
            "254      208.0    264.0\n",
            "255      157.0    228.0\n",
            "256       16.0     57.0\n",
            "257      215.0    772.0\n",
            "258      235.0    160.0\n",
            "259      149.0    373.0\n",
            "260      310.0    445.0\n",
            "261       41.0     43.0\n",
            "262       80.0     61.0\n",
            "263      196.0    143.0\n",
            "264      233.0    146.0\n",
            "265       88.0     37.0\n",
            "266       22.0    191.0\n",
            "267      287.0    288.0\n",
            "268      162.0     50.0\n",
            "269       51.0    101.0\n",
            "270       62.0     72.0\n",
            "271      -20.0    316.0\n",
            "272      -19.0    227.0\n",
            "273       55.0    139.0\n",
            "274       35.0    159.0\n",
            "275      163.0    185.0\n",
            "276      250.0    188.0\n",
            "277      101.0    527.0\n",
            "278        6.0     95.0\n",
            "279      225.0    839.0\n",
            "280      214.0    127.0\n",
            "281      147.0     82.0\n",
            "282     -263.0     39.0\n",
            "283      252.0    125.0\n",
            "284      563.0   3823.0\n",
            "285      122.0     78.0\n",
            "286      339.0     70.0\n",
            "287       58.0     44.0\n",
            "288       36.0     60.0\n",
            "289      319.0     81.0\n",
            "290      110.0    635.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "unique_test_groups = np.unique(group_labels)\n",
        "prediction_counts = np.zeros(len(unique_test_groups)+1)\n",
        "actual_counts = np.zeros(len(unique_test_groups)+1)\n",
        "y = df[\"countts\"].copy()\n",
        "\n",
        "for group in unique_test_groups:\n",
        "    group_predictions = predictions[group_labels == group]\n",
        "    group_actual = y[group_labels == group]\n",
        "    prediction_counts[group] = np.int32(np.sum(group_predictions))\n",
        "    actual_counts[group] = np.int32(np.sum(group_actual))\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "count_results = pd.DataFrame({'Predicted': prediction_counts, 'Actual': actual_counts})\n",
        "count_results = count_results[1:]\n",
        "print(count_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bru6wwCTNuFb",
        "outputId": "d77ed752-4de5-4aaf-e3c2-a4f2cf83e821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE: 79.78491725527222\n",
            "R2: 0.03324195731669122\n"
          ]
        }
      ],
      "source": [
        "print(\"MAPE:\", mape(actual_counts[1:], prediction_counts[1:]))\n",
        "print(\"R2:\", r2_score(actual_counts[1:], prediction_counts[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "pthHqC5FNt7m",
        "outputId": "2e2ecc9d-bb99-4c0d-b1bd-1653d2d76940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-ad891f454cbc>:13: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.\n",
            "  ax.set_xlim(min_value, max_value)\n",
            "<ipython-input-20-ad891f454cbc>:14: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  ax.set_ylim(min_value, max_value)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.scatter(actual_counts, prediction_counts, color='blue', label='Actual vs Predicted')\n",
        "ax.set_xlabel('Actual')\n",
        "ax.set_ylabel('Predicted')\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "# Set the x-axis and y-axis limits to be equal\n",
        "min_value = min(np.min(actual_counts), np.min(prediction_counts))\n",
        "max_value = max(np.max(actual_counts), np.max(prediction_counts))\n",
        "ax.set_xlim(min_value, max_value)\n",
        "ax.set_ylim(min_value, max_value)\n",
        "# ax.set_aspect('equal')\n",
        "plt.axis('equal')\n",
        "\n",
        "# Draw a line representing y=x\n",
        "ax.plot([min_value, max_value], [min_value, max_value], color='red', linestyle='-', label='y=x')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIM4or869k1",
        "outputId": "e5531672-d7a7-4042-d1b4-cc0360a6dc8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AE: 41.0 89.0 200.0\n"
          ]
        }
      ],
      "source": [
        "ae = np.abs(prediction_counts[1:] - actual_counts[1:])\n",
        "q25 = np.percentile(ae, 25)\n",
        "q50 = np.percentile(ae, 50)\n",
        "q75 = np.percentile(ae, 75)\n",
        "print(\"AE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1cvhJjN_oo",
        "outputId": "9ab1c865-2c30-4fb3-e2fd-20c205791c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APE: 30.518394648829435 61.481818181818184 88.22224309158781\n"
          ]
        }
      ],
      "source": [
        "ape = np.abs(prediction_counts[1:] - actual_counts[1:])/actual_counts[1:] * 100\n",
        "q25 = np.percentile(ape, 25)\n",
        "q50 = np.percentile(ape, 50)\n",
        "q75 = np.percentile(ape, 75)\n",
        "print(\"APE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp0pH5veN_lO",
        "outputId": "5c65035e-0bd0-47c3-ea72-953655995e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRMSE: 1832.6722016294757\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "y_true_mean = np.mean(actual_counts)\n",
        "\n",
        "y_true_centered = actual_counts - y_true_mean\n",
        "y_pred_centered = prediction_counts - y_true_mean\n",
        "\n",
        "crmse = np.sqrt(mean_squared_error(y_true_centered, y_pred_centered))\n",
        "\n",
        "print(\"CRMSE:\", crmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVkeMIIWzthy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W39QmbETztai"
      },
      "outputs": [],
      "source": [
        "# If we remove the three extreme events, the results of R2 and CRMSE would be much better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVFPq3u9N_gS"
      },
      "outputs": [],
      "source": [
        "new_prediction_counts = prediction_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugJaRbFjuYhs",
        "outputId": "71ed9823-342a-4fa3-d229-78a4820013bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16022.0\n",
            "1540.0\n",
            "15829.0\n",
            "21377.0\n"
          ]
        }
      ],
      "source": [
        "print(actual_counts[29])\n",
        "print(new_prediction_counts[29])\n",
        "\n",
        "print(actual_counts[33])\n",
        "print(actual_counts[209])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fLXzega69hS"
      },
      "outputs": [],
      "source": [
        "new_prediction_counts[29] = 16022\n",
        "new_prediction_counts[33] = 15829\n",
        "new_prediction_counts[209] = 21377"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCXdT6RY2glU",
        "outputId": "bd926506-34d6-4bf1-ba69-a43346a7c87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE: 71.35884879231948\n",
            "R2: 0.9194698811188228\n"
          ]
        }
      ],
      "source": [
        "print(\"MAPE:\", mape(actual_counts[1:], new_prediction_counts[1:]))\n",
        "print(\"R2:\", r2_score(actual_counts[1:], new_prediction_counts[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqv4qTnZvvxW",
        "outputId": "c4c55434-29d8-41b1-a891-f961b00c93b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRMSE: 528.9383616055909\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "y_true_mean = np.mean(actual_counts)\n",
        "\n",
        "y_true_centered = actual_counts - y_true_mean\n",
        "y_pred_centered = new_prediction_counts - y_true_mean\n",
        "\n",
        "crmse = np.sqrt(mean_squared_error(y_true_centered, y_pred_centered))\n",
        "\n",
        "print(\"CRMSE:\", crmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_5N9I4Nvvqi",
        "outputId": "276983c5-6a3d-468d-aa47-c38f14a70509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AE: 38.0 77.5 181.0\n"
          ]
        }
      ],
      "source": [
        "ae = np.abs(new_prediction_counts[1:] - actual_counts[1:])\n",
        "q25 = np.percentile(ae, 25)\n",
        "q50 = np.percentile(ae, 50)\n",
        "q75 = np.percentile(ae, 75)\n",
        "print(\"AE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MZs6SaLwj1n",
        "outputId": "f7ee0883-9668-4e7e-c66d-ae43c9ef710a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APE: 24.91788410628493 53.15181518151816 83.98168394091753\n"
          ]
        }
      ],
      "source": [
        "ape = np.abs(new_prediction_counts[1:] - actual_counts[1:])/actual_counts[1:] * 100\n",
        "q25 = np.percentile(ape, 25)\n",
        "q50 = np.percentile(ape, 50)\n",
        "q75 = np.percentile(ape, 75)\n",
        "print(\"APE:\", q25, q50, q75)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
