{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "Y9xnmqW32Ys_",
        "outputId": "1290ebe9-96c0-4698-989f-506311854323"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-29 16:08:34.994196: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-29 16:08:34.997501: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-08-29 16:08:35.057054: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-08-29 16:08:35.060371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-29 16:08:35.971880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>medWDIR10</th>\n",
              "      <th>WLANDMASK</th>\n",
              "      <th>WHGT</th>\n",
              "      <th>WLAI</th>\n",
              "      <th>LAI</th>\n",
              "      <th>medWDIR</th>\n",
              "      <th>difWDIR</th>\n",
              "      <th>outageLength</th>\n",
              "      <th>binaryts</th>\n",
              "      <th>countts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>1</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>2.913192</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>99.984551</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>1</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>101.489599</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>1</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>89.999149</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>1</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>2.925068</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>-253.901195</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>1</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>2.947943</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>100.359308</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 395 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ...  medWDIR10 WLANDMASK  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...  72.641768         1   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...  68.455052         1   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...  65.798428         1   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...  74.041407         1   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...  74.038184         1   \n",
              "\n",
              "         WHGT      WLAI       LAI    medWDIR     difWDIR  outageLength  \\\n",
              "0  143.317993  2.913192  3.274934  72.641768   99.984551            48   \n",
              "1  113.597603  1.000000  3.307087  68.455052  101.489599            48   \n",
              "2   80.900375  1.000000  3.307087  65.798428   89.999149            48   \n",
              "3  150.076904  2.925068  3.274934  74.041407 -253.901195            48   \n",
              "4  123.888351  2.947943  3.274934  74.038184  100.359308            48   \n",
              "\n",
              "   binaryts  countts  \n",
              "0         0        0  \n",
              "1         0        0  \n",
              "2         0        0  \n",
              "3         1        1  \n",
              "4         1        1  \n",
              "\n",
              "[5 rows x 395 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.utils import set_random_seed\n",
        "\n",
        "df = pd.read_csv('Data/WRF4.2.2_4km_calibrationFile_Eversource_Rainwind_294events_2023-11-17_CT 12.18.32 PM.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bRadNP1T2g9Q",
        "outputId": "63237c86-3827-46d1-ef29-a8ae87f53b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group Label: 1, Event Code: CT-2005100800\n",
            "Group Label: 2, Event Code: CT-2005101512\n",
            "Group Label: 3, Event Code: CT-2005102418\n",
            "Group Label: 4, Event Code: CT-2006011706\n",
            "Group Label: 5, Event Code: CT-2006021700\n",
            "Group Label: 6, Event Code: CT-2006060700\n",
            "Group Label: 7, Event Code: CT-2006090118\n",
            "Group Label: 8, Event Code: CT-2006102000\n",
            "Group Label: 9, Event Code: CT-2006102800\n",
            "Group Label: 10, Event Code: CT-2007041506\n",
            "Group Label: 11, Event Code: CT-2008030800\n",
            "Group Label: 12, Event Code: CT-2008032100\n",
            "Group Label: 13, Event Code: CT-2008090600\n",
            "Group Label: 14, Event Code: CT-2008102506\n",
            "Group Label: 15, Event Code: CT-2008121100\n",
            "Group Label: 16, Event Code: CT-2008122406\n",
            "Group Label: 17, Event Code: CT-2008123006\n",
            "Group Label: 18, Event Code: CT-2009050906\n",
            "Group Label: 19, Event Code: CT-2009100700\n",
            "Group Label: 20, Event Code: CT-2009112800\n",
            "Group Label: 21, Event Code: CT-2009120300\n",
            "Group Label: 22, Event Code: CT-2010012500\n",
            "Group Label: 23, Event Code: CT-2010031300\n",
            "Group Label: 24, Event Code: CT-2010042818\n",
            "Group Label: 25, Event Code: CT-2010050806\n",
            "Group Label: 26, Event Code: CT-2010082212\n",
            "Group Label: 27, Event Code: CT-2010093006\n",
            "Group Label: 28, Event Code: CT-2010120100\n",
            "Group Label: 29, Event Code: CT-2011082800\n",
            "Group Label: 30, Event Code: CT-2011120700\n",
            "Group Label: 31, Event Code: CT-2011122712\n",
            "Group Label: 32, Event Code: CT-2012091800\n",
            "Group Label: 33, Event Code: CT-2012102806\n",
            "Group Label: 34, Event Code: CT-2013013012\n",
            "Group Label: 35, Event Code: CT-2013051106\n",
            "Group Label: 36, Event Code: CT-2013052312\n",
            "Group Label: 37, Event Code: CT-2013052506\n",
            "Group Label: 38, Event Code: CT-2013060712\n",
            "Group Label: 39, Event Code: CT-2013061306\n",
            "Group Label: 40, Event Code: CT-2013103112\n",
            "Group Label: 41, Event Code: CT-2013111900\n",
            "Group Label: 42, Event Code: CT-2013112612\n",
            "Group Label: 43, Event Code: CT-2014010606\n",
            "Group Label: 44, Event Code: CT-2014041400\n",
            "Group Label: 45, Event Code: CT-2014051600\n",
            "Group Label: 46, Event Code: CT-2014061800\n",
            "Group Label: 47, Event Code: CT-2014100700\n",
            "Group Label: 48, Event Code: CT-2014102200\n",
            "Group Label: 49, Event Code: CT-2014110118\n",
            "Group Label: 50, Event Code: CT-2015010800\n",
            "Group Label: 51, Event Code: CT-2015080600\n",
            "Group Label: 52, Event Code: CT-2015081106\n",
            "Group Label: 53, Event Code: CT-2015091018\n",
            "Group Label: 54, Event Code: CT-2015102806\n",
            "Group Label: 55, Event Code: CT-2015110606\n",
            "Group Label: 56, Event Code: CT-2015111212\n",
            "Group Label: 57, Event Code: CT-2015111818\n",
            "Group Label: 58, Event Code: CT-2015121418\n",
            "Group Label: 59, Event Code: CT-2016010918\n",
            "Group Label: 60, Event Code: CT-2016011518\n",
            "Group Label: 61, Event Code: CT-2016011912\n",
            "Group Label: 62, Event Code: CT-2016012800\n",
            "Group Label: 63, Event Code: CT-2016021300\n",
            "Group Label: 64, Event Code: CT-2016021518\n",
            "Group Label: 65, Event Code: CT-2016021918\n",
            "Group Label: 66, Event Code: CT-2016022818\n",
            "Group Label: 67, Event Code: CT-2016030100\n",
            "Group Label: 68, Event Code: CT-2016031706\n",
            "Group Label: 69, Event Code: CT-2016032818\n",
            "Group Label: 70, Event Code: CT-2016040706\n",
            "Group Label: 71, Event Code: CT-2016090400\n",
            "Group Label: 72, Event Code: CT-2016092318\n",
            "Group Label: 73, Event Code: CT-2016092818\n",
            "Group Label: 74, Event Code: CT-2016110306\n",
            "Group Label: 75, Event Code: CT-2016111106\n",
            "Group Label: 76, Event Code: CT-2016120812\n",
            "Group Label: 77, Event Code: CT-2016121200\n",
            "Group Label: 78, Event Code: CT-2016121500\n",
            "Group Label: 79, Event Code: CT-2016121718\n",
            "Group Label: 80, Event Code: CT-2016122400\n",
            "Group Label: 81, Event Code: CT-2017010100\n",
            "Group Label: 82, Event Code: CT-2017010418\n",
            "Group Label: 83, Event Code: CT-2017011006\n",
            "Group Label: 84, Event Code: CT-2017011706\n",
            "Group Label: 85, Event Code: CT-2017012306\n",
            "Group Label: 86, Event Code: CT-2017020112\n",
            "Group Label: 87, Event Code: CT-2017031018\n",
            "Group Label: 88, Event Code: CT-2017031606\n",
            "Group Label: 89, Event Code: CT-2017041212\n",
            "Group Label: 90, Event Code: CT-2017041612\n",
            "Group Label: 91, Event Code: CT-2017042506\n",
            "Group Label: 92, Event Code: CT-2017042900\n",
            "Group Label: 93, Event Code: CT-2017050200\n",
            "Group Label: 94, Event Code: CT-2017050506\n",
            "Group Label: 95, Event Code: CT-2017051300\n",
            "Group Label: 96, Event Code: CT-2017051500\n",
            "Group Label: 97, Event Code: CT-2017051806\n",
            "Group Label: 98, Event Code: CT-2017052506\n",
            "Group Label: 99, Event Code: CT-2017060506\n",
            "Group Label: 100, Event Code: CT-2017061600\n",
            "Group Label: 101, Event Code: CT-2017072400\n",
            "Group Label: 102, Event Code: CT-2017072900\n",
            "Group Label: 103, Event Code: CT-2017081806\n",
            "Group Label: 104, Event Code: CT-2017082912\n",
            "Group Label: 105, Event Code: CT-2017090300\n",
            "Group Label: 106, Event Code: CT-2017090512\n",
            "Group Label: 107, Event Code: CT-2017091918\n",
            "Group Label: 108, Event Code: CT-2017100900\n",
            "Group Label: 109, Event Code: CT-2017101506\n",
            "Group Label: 110, Event Code: CT-2017102400\n",
            "Group Label: 111, Event Code: CT-2017102912\n",
            "Group Label: 112, Event Code: CT-2017110606\n",
            "Group Label: 113, Event Code: CT-2017111000\n",
            "Group Label: 114, Event Code: CT-2017111612\n",
            "Group Label: 115, Event Code: CT-2017111818\n",
            "Group Label: 116, Event Code: CT-2017112206\n",
            "Group Label: 117, Event Code: CT-2017120512\n",
            "Group Label: 118, Event Code: CT-2017120906\n",
            "Group Label: 119, Event Code: CT-2017122218\n",
            "Group Label: 120, Event Code: CT-2018010406\n",
            "Group Label: 121, Event Code: CT-2018012312\n",
            "Group Label: 122, Event Code: CT-2018020418\n",
            "Group Label: 123, Event Code: CT-2018020706\n",
            "Group Label: 124, Event Code: CT-2018021718\n",
            "Group Label: 125, Event Code: CT-2018022418\n",
            "Group Label: 126, Event Code: CT-2018030200\n",
            "Group Label: 127, Event Code: CT-2018040412\n",
            "Group Label: 128, Event Code: CT-2018041600\n",
            "Group Label: 129, Event Code: CT-2018060306\n",
            "Group Label: 130, Event Code: CT-2018062800\n",
            "Group Label: 131, Event Code: CT-2018072200\n",
            "Group Label: 132, Event Code: CT-2018091000\n",
            "Group Label: 133, Event Code: CT-2018101112\n",
            "Group Label: 134, Event Code: CT-2018101512\n",
            "Group Label: 135, Event Code: CT-2018101706\n",
            "Group Label: 136, Event Code: CT-2018102100\n",
            "Group Label: 137, Event Code: CT-2018102706\n",
            "Group Label: 138, Event Code: CT-2018102900\n",
            "Group Label: 139, Event Code: CT-2018110300\n",
            "Group Label: 140, Event Code: CT-2018110612\n",
            "Group Label: 141, Event Code: CT-2018110900\n",
            "Group Label: 142, Event Code: CT-2018111306\n",
            "Group Label: 143, Event Code: CT-2018111518\n",
            "Group Label: 144, Event Code: CT-2018112612\n",
            "Group Label: 145, Event Code: CT-2018112812\n",
            "Group Label: 146, Event Code: CT-2018120300\n",
            "Group Label: 147, Event Code: CT-2018121712\n",
            "Group Label: 148, Event Code: CT-2018122106\n",
            "Group Label: 149, Event Code: CT-2018122800\n",
            "Group Label: 150, Event Code: CT-2019010100\n",
            "Group Label: 151, Event Code: CT-2019010512\n",
            "Group Label: 152, Event Code: CT-2019010900\n",
            "Group Label: 153, Event Code: CT-2019012318\n",
            "Group Label: 154, Event Code: CT-2019020800\n",
            "Group Label: 155, Event Code: CT-2019021212\n",
            "Group Label: 156, Event Code: CT-2019022012\n",
            "Group Label: 157, Event Code: CT-2019022500\n",
            "Group Label: 158, Event Code: CT-2019031000\n",
            "Group Label: 159, Event Code: CT-2019031512\n",
            "Group Label: 160, Event Code: CT-2019032200\n",
            "Group Label: 161, Event Code: CT-2019033100\n",
            "Group Label: 162, Event Code: CT-2019040300\n",
            "Group Label: 163, Event Code: CT-2019041218\n",
            "Group Label: 164, Event Code: CT-2019041912\n",
            "Group Label: 165, Event Code: CT-2019042606\n",
            "Group Label: 166, Event Code: CT-2019051000\n",
            "Group Label: 167, Event Code: CT-2019051300\n",
            "Group Label: 168, Event Code: CT-2019052312\n",
            "Group Label: 169, Event Code: CT-2019052812\n",
            "Group Label: 170, Event Code: CT-2019061306\n",
            "Group Label: 171, Event Code: CT-2019070606\n",
            "Group Label: 172, Event Code: CT-2019081312\n",
            "Group Label: 173, Event Code: CT-2019082812\n",
            "Group Label: 174, Event Code: CT-2019092312\n",
            "Group Label: 175, Event Code: CT-2019100312\n",
            "Group Label: 176, Event Code: CT-2019100700\n",
            "Group Label: 177, Event Code: CT-2019101000\n",
            "Group Label: 178, Event Code: CT-2019101612\n",
            "Group Label: 179, Event Code: CT-2019102218\n",
            "Group Label: 180, Event Code: CT-2019102700\n",
            "Group Label: 181, Event Code: CT-2019103112\n",
            "Group Label: 182, Event Code: CT-2019110712\n",
            "Group Label: 183, Event Code: CT-2019111200\n",
            "Group Label: 184, Event Code: CT-2019112718\n",
            "Group Label: 185, Event Code: CT-2019120906\n",
            "Group Label: 186, Event Code: CT-2019121318\n",
            "Group Label: 187, Event Code: CT-2020011106\n",
            "Group Label: 188, Event Code: CT-2020011606\n",
            "Group Label: 189, Event Code: CT-2020012512\n",
            "Group Label: 190, Event Code: CT-2020020700\n",
            "Group Label: 191, Event Code: CT-2020021300\n",
            "Group Label: 192, Event Code: CT-2020021812\n",
            "Group Label: 193, Event Code: CT-2020022700\n",
            "Group Label: 194, Event Code: CT-2020030318\n",
            "Group Label: 195, Event Code: CT-2020030618\n",
            "Group Label: 196, Event Code: CT-2020031300\n",
            "Group Label: 197, Event Code: CT-2020031906\n",
            "Group Label: 198, Event Code: CT-2020032818\n",
            "Group Label: 199, Event Code: CT-2020040218\n",
            "Group Label: 200, Event Code: CT-2020040912\n",
            "Group Label: 201, Event Code: CT-2020041300\n",
            "Group Label: 202, Event Code: CT-2020041718\n",
            "Group Label: 203, Event Code: CT-2020042112\n",
            "Group Label: 204, Event Code: CT-2020042406\n",
            "Group Label: 205, Event Code: CT-2020042612\n",
            "Group Label: 206, Event Code: CT-2020043018\n",
            "Group Label: 207, Event Code: CT-2020051512\n",
            "Group Label: 208, Event Code: CT-2020071012\n",
            "Group Label: 209, Event Code: CT-2020080406\n",
            "Group Label: 210, Event Code: CT-2020081612\n",
            "Group Label: 211, Event Code: CT-2020082900\n",
            "Group Label: 212, Event Code: CT-2020093000\n",
            "Group Label: 213, Event Code: CT-2020100706\n",
            "Group Label: 214, Event Code: CT-2020101206\n",
            "Group Label: 215, Event Code: CT-2020101612\n",
            "Group Label: 216, Event Code: CT-2020102906\n",
            "Group Label: 217, Event Code: CT-2020110112\n",
            "Group Label: 218, Event Code: CT-2020110200\n",
            "Group Label: 219, Event Code: CT-2020111100\n",
            "Group Label: 220, Event Code: CT-2020111512\n",
            "Group Label: 221, Event Code: CT-2020112218\n",
            "Group Label: 222, Event Code: CT-2020113000\n",
            "Group Label: 223, Event Code: CT-2020120500\n",
            "Group Label: 224, Event Code: CT-2021011518\n",
            "Group Label: 225, Event Code: CT-2021030118\n",
            "Group Label: 226, Event Code: CT-2021031200\n",
            "Group Label: 227, Event Code: CT-2021031412\n",
            "Group Label: 228, Event Code: CT-2021031812\n",
            "Group Label: 229, Event Code: CT-2021032506\n",
            "Group Label: 230, Event Code: CT-2021032600\n",
            "Group Label: 231, Event Code: CT-2021032812\n",
            "Group Label: 232, Event Code: CT-2021041506\n",
            "Group Label: 233, Event Code: CT-2021042112\n",
            "Group Label: 234, Event Code: CT-2021042500\n",
            "Group Label: 235, Event Code: CT-2021042918\n",
            "Group Label: 236, Event Code: CT-2021052900\n",
            "Group Label: 237, Event Code: CT-2021070118\n",
            "Group Label: 238, Event Code: CT-2021070806\n",
            "Group Label: 239, Event Code: CT-2021072918\n",
            "Group Label: 240, Event Code: CT-2021081900\n",
            "Group Label: 241, Event Code: CT-2021082206\n",
            "Group Label: 242, Event Code: CT-2021090100\n",
            "Group Label: 243, Event Code: CT-2021090112\n",
            "Group Label: 244, Event Code: CT-2021090812\n",
            "Group Label: 245, Event Code: CT-2021100318\n",
            "Group Label: 246, Event Code: CT-2021101612\n",
            "Group Label: 247, Event Code: CT-2021102600\n",
            "Group Label: 248, Event Code: CT-2021102918\n",
            "Group Label: 249, Event Code: CT-2021111118\n",
            "Group Label: 250, Event Code: CT-2021111318\n",
            "Group Label: 251, Event Code: CT-2021111818\n",
            "Group Label: 252, Event Code: CT-2021112200\n",
            "Group Label: 253, Event Code: CT-2021112606\n",
            "Group Label: 254, Event Code: CT-2021120600\n",
            "Group Label: 255, Event Code: CT-2021121112\n",
            "Group Label: 256, Event Code: CT-2022020718\n",
            "Group Label: 257, Event Code: CT-2022021712\n",
            "Group Label: 258, Event Code: CT-2022022212\n",
            "Group Label: 259, Event Code: CT-2022030706\n",
            "Group Label: 260, Event Code: CT-2022031206\n",
            "Group Label: 261, Event Code: CT-2022031906\n",
            "Group Label: 262, Event Code: CT-2022032400\n",
            "Group Label: 263, Event Code: CT-2022033106\n",
            "Group Label: 264, Event Code: CT-2022033112\n",
            "Group Label: 265, Event Code: CT-2022040518\n",
            "Group Label: 266, Event Code: CT-2022040706\n",
            "Group Label: 267, Event Code: CT-2022041818\n",
            "Group Label: 268, Event Code: CT-2022050400\n",
            "Group Label: 269, Event Code: CT-2022050700\n",
            "Group Label: 270, Event Code: CT-2022051906\n",
            "Group Label: 271, Event Code: CT-2022090418\n",
            "Group Label: 272, Event Code: CT-2022092306\n",
            "Group Label: 273, Event Code: CT-2022100106\n",
            "Group Label: 274, Event Code: CT-2022100400\n",
            "Group Label: 275, Event Code: CT-2022101300\n",
            "Group Label: 276, Event Code: CT-2022101306\n",
            "Group Label: 277, Event Code: CT-2022111112\n",
            "Group Label: 278, Event Code: CT-2022112712\n",
            "Group Label: 279, Event Code: CT-2022113006\n",
            "Group Label: 280, Event Code: CT-2022120300\n",
            "Group Label: 281, Event Code: CT-2022120612\n",
            "Group Label: 282, Event Code: CT-2022121100\n",
            "Group Label: 283, Event Code: CT-2022121518\n",
            "Group Label: 284, Event Code: CT-2022122218\n",
            "Group Label: 285, Event Code: CT-2023010318\n",
            "Group Label: 286, Event Code: CT-2023011212\n",
            "Group Label: 287, Event Code: CT-2023011900\n",
            "Group Label: 288, Event Code: CT-2023012218\n",
            "Group Label: 289, Event Code: CT-2023012512\n",
            "Group Label: 290, Event Code: CT-2023020218\n"
          ]
        }
      ],
      "source": [
        "df = df.iloc[:236350, :]\n",
        "event_codes = df[\"eventCode\"]\n",
        "group_labels = np.zeros(len(df), dtype=int)\n",
        "\n",
        "current_label = 0\n",
        "previous_code = None\n",
        "\n",
        "for i, code in enumerate(event_codes):\n",
        "    if code != previous_code:\n",
        "        current_label += 1\n",
        "        previous_code = code\n",
        "    group_labels[i] = current_label\n",
        "\n",
        "unique_codes, unique_indices = np.unique(event_codes, return_index=True)\n",
        "for code, index in zip(unique_codes, unique_indices):\n",
        "    print(f\"Group Label: {group_labels[index]}, Event Code: {code}\")\n",
        "\n",
        "df[\"groupLabel\"] = group_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "onz2YEbi51eK",
        "outputId": "e4564972-481e-40bd-e6be-c36ff8d68292"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>WLANDMASK</th>\n",
              "      <th>WHGT</th>\n",
              "      <th>WLAI</th>\n",
              "      <th>LAI</th>\n",
              "      <th>medWDIR</th>\n",
              "      <th>difWDIR</th>\n",
              "      <th>outageLength</th>\n",
              "      <th>binaryts</th>\n",
              "      <th>countts</th>\n",
              "      <th>groupLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>2.913192</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>72.641768</td>\n",
              "      <td>99.984551</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>68.455052</td>\n",
              "      <td>101.489599</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.307087</td>\n",
              "      <td>65.798428</td>\n",
              "      <td>89.999149</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>2.925068</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.041407</td>\n",
              "      <td>-253.901195</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>2.947943</td>\n",
              "      <td>3.274934</td>\n",
              "      <td>74.038184</td>\n",
              "      <td>100.359308</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 396 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ... WLANDMASK        WHGT  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...         1  143.317993   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...         1  113.597603   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...         1   80.900375   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...         1  150.076904   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...         1  123.888351   \n",
              "\n",
              "       WLAI       LAI    medWDIR     difWDIR  outageLength  binaryts  countts  \\\n",
              "0  2.913192  3.274934  72.641768   99.984551            48         0        0   \n",
              "1  1.000000  3.307087  68.455052  101.489599            48         0        0   \n",
              "2  1.000000  3.307087  65.798428   89.999149            48         0        0   \n",
              "3  2.925068  3.274934  74.041407 -253.901195            48         1        1   \n",
              "4  2.947943  3.274934  74.038184  100.359308            48         1        1   \n",
              "\n",
              "   groupLabel  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "\n",
              "[5 rows x 396 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "XaGEEz3i4nXF",
        "outputId": "fcdb3937-1b27-4628-b226-a669e641103f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventCode</th>\n",
              "      <th>stormCode</th>\n",
              "      <th>eventLength</th>\n",
              "      <th>gridID</th>\n",
              "      <th>gridIDwrf</th>\n",
              "      <th>gIDwrf</th>\n",
              "      <th>latwrf</th>\n",
              "      <th>lonwrf</th>\n",
              "      <th>Territory</th>\n",
              "      <th>HGT</th>\n",
              "      <th>...</th>\n",
              "      <th>prec43</th>\n",
              "      <th>prec52</th>\n",
              "      <th>prec71</th>\n",
              "      <th>prec81</th>\n",
              "      <th>prec82</th>\n",
              "      <th>prec90</th>\n",
              "      <th>prec95</th>\n",
              "      <th>elvDiff</th>\n",
              "      <th>prec42</th>\n",
              "      <th>countts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16974</td>\n",
              "      <td>g16974</td>\n",
              "      <td>16974</td>\n",
              "      <td>41.106861</td>\n",
              "      <td>-73.698273</td>\n",
              "      <td>CT</td>\n",
              "      <td>143.317993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.121396</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>0.012747</td>\n",
              "      <td>0.016085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.877557</td>\n",
              "      <td>0.015478</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16975</td>\n",
              "      <td>g16975</td>\n",
              "      <td>16975</td>\n",
              "      <td>41.070957</td>\n",
              "      <td>-73.701202</td>\n",
              "      <td>CT</td>\n",
              "      <td>113.597603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137568</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>0.002904</td>\n",
              "      <td>0.011978</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>0.002178</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>-1.215946</td>\n",
              "      <td>0.008348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g16976</td>\n",
              "      <td>g16976</td>\n",
              "      <td>16976</td>\n",
              "      <td>41.035046</td>\n",
              "      <td>-73.704132</td>\n",
              "      <td>CT</td>\n",
              "      <td>80.900375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024931</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-10.089323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17156</td>\n",
              "      <td>g17156</td>\n",
              "      <td>17156</td>\n",
              "      <td>41.140549</td>\n",
              "      <td>-73.647644</td>\n",
              "      <td>CT</td>\n",
              "      <td>150.076904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156550</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.018104</td>\n",
              "      <td>0.021832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.180551</td>\n",
              "      <td>0.007455</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CT-2005100800</td>\n",
              "      <td>2005100800</td>\n",
              "      <td>48</td>\n",
              "      <td>g17157</td>\n",
              "      <td>g17157</td>\n",
              "      <td>17157</td>\n",
              "      <td>41.104641</td>\n",
              "      <td>-73.650635</td>\n",
              "      <td>CT</td>\n",
              "      <td>123.888351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.207087</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.015135</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.033832</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>2.104055</td>\n",
              "      <td>0.021189</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 98 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eventCode   stormCode  eventLength  gridID gridIDwrf  gIDwrf  \\\n",
              "0  CT-2005100800  2005100800           48  g16974    g16974   16974   \n",
              "1  CT-2005100800  2005100800           48  g16975    g16975   16975   \n",
              "2  CT-2005100800  2005100800           48  g16976    g16976   16976   \n",
              "3  CT-2005100800  2005100800           48  g17156    g17156   17156   \n",
              "4  CT-2005100800  2005100800           48  g17157    g17157   17157   \n",
              "\n",
              "      latwrf     lonwrf Territory         HGT  ...    prec43    prec52  \\\n",
              "0  41.106861 -73.698273        CT  143.317993  ...  0.121396  0.001517   \n",
              "1  41.070957 -73.701202        CT  113.597603  ...  0.137568  0.001815   \n",
              "2  41.035046 -73.704132        CT   80.900375  ...  0.024931  0.000000   \n",
              "3  41.140549 -73.647644        CT  150.076904  ...  0.156550  0.002130   \n",
              "4  41.104641 -73.650635        CT  123.888351  ...  0.207087  0.000890   \n",
              "\n",
              "     prec71    prec81    prec82    prec90    prec95    elvDiff    prec42  \\\n",
              "0  0.012747  0.016085  0.000000  0.028832  0.000000  12.877557  0.015478   \n",
              "1  0.002904  0.011978  0.000363  0.002178  0.000363  -1.215946  0.008348   \n",
              "2  0.005540  0.000000  0.000000  0.011080  0.000000 -10.089323  0.000000   \n",
              "3  0.018104  0.021832  0.000000  0.023429  0.000000   5.180551  0.007455   \n",
              "4  0.015135  0.018519  0.000712  0.033832  0.000712   2.104055  0.021189   \n",
              "\n",
              "   countts  \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        1  \n",
              "4        1  \n",
              "\n",
              "[5 rows x 98 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# constant features\n",
        "constant_df = df.iloc[:, :97]\n",
        "constant_df[\"countts\"] = df[\"countts\"]\n",
        "constant_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VFMIj9o62gzG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kH_xDVW2gwO",
        "outputId": "d1eb5b87-5f2e-48d9-d7ac-d3355c4feebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(815, 20)\n"
          ]
        }
      ],
      "source": [
        "# select 20 constant features based on pearson correlation value, and then get the costant adjacency matrix\n",
        "# there is only one constant matrix for all the events\n",
        "\n",
        "y = df[\"countts\"].copy()\n",
        "X_constant = df[[\"land21\", \"fuseCount\", \"landTotal\", \"ohLength\", \"poleCount\",\n",
        "        \"reclrCount\", \"land22\", \"land24\", \"land23\", \"land43\", \"latwrf\",\n",
        "        \"avgHardSDI\", \"avgHardBA\", \"soilDepth\", \"stdHardBA\", \"hydNo\",\n",
        "        \"prec81\", \"avgTPA\", \"stdHardSDI\", \"avgSDI\"\n",
        "     ]]\n",
        "\n",
        "X_constant = X_constant.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X_constant = scaler.fit_transform(X_constant)\n",
        "\n",
        "constant_reshaped_data = X_constant.reshape(290, 815, 20)\n",
        "constant_reshaped_data = constant_reshaped_data[0,:,:]\n",
        "print(constant_reshaped_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mzdlCQOZ2gtY"
      },
      "outputs": [],
      "source": [
        "def mean_cosine_similarity(arr1, arr2):\n",
        "    norm1 = np.linalg.norm(arr1)\n",
        "    norm2 = np.linalg.norm(arr2)\n",
        "    arr1 = arr1 / norm1\n",
        "    arr2 = arr2 / norm2\n",
        "    similarities = np.sum(arr1 * arr2)\n",
        "    return np.mean(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHtYEsqDEynJ"
      },
      "outputs": [],
      "source": [
        "n_nodes = constant_reshaped_data.shape[0]\n",
        "constant_adjacency_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "similarity_matrix = np.zeros((n_nodes, n_nodes))\n",
        "for i in range(n_nodes):\n",
        "    for j in range(i + 1, n_nodes):\n",
        "        similarity = mean_cosine_similarity(constant_reshaped_data[i], constant_reshaped_data[j])\n",
        "        similarity_matrix[i, j] = similarity\n",
        "        similarity_matrix[j, i] = similarity\n",
        "\n",
        "nearest_neighbors = np.argsort(-similarity_matrix, axis=1)[:, 1:9]   # number of neighbors, hyperparameter tuning\n",
        "\n",
        "eighth_neighbors = np.sort(similarity_matrix, axis=1)[:, -8]  # Get the 8th largest value\n",
        "average_eighth_neighbor_value = np.mean(eighth_neighbors)\n",
        "threshold = average_eighth_neighbor_value\n",
        "\n",
        "nearest_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "for k in range(n_nodes):\n",
        "    nearest_matrix[k, nearest_neighbors[k]] = 1\n",
        "constant_adjacency_matrix[(similarity_matrix > threshold) & (nearest_matrix == 1)] = 1\n",
        "\n",
        "np.save(\"/home/xus23004/Project/OPM/Results/constant_adjacency_matrix.npy\", constant_adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMTv0tbW6aMH"
      },
      "outputs": [],
      "source": [
        "constant_adjacency_matrix = np.load(\"/content/drive/MyDrive/constant_adjacent.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZHn7LPrEykR"
      },
      "outputs": [],
      "source": [
        "# dynamic features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylAMg0GXEyeV",
        "outputId": "996d9d04-d998-47f0-9d11-3f01a2f33f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(290, 815, 30)\n"
          ]
        }
      ],
      "source": [
        "# select 30 dynamic features based on pearson correlation value, and then get the dynamic adjacency matrix\n",
        "# each event has its own dynamic adjacency matrix\n",
        "\n",
        "X_dynamic = df[[\"binaryts\", \"coggt27\", \"ggt27\", \"ggt22\", \"coggt22\",\n",
        "        \"stdW850\", \"maxGUST\", \"peakW850\", \"maxW850\", \"peakGUST\", \"avgAFWA_CAPE\",\n",
        "        \"avgSSRUN\", \"peakAFWA_LLWS\", \"peakSSRUN\", \"coggt17\", \"maxSSRUN\", \"stdAFWA_RAIN\",\n",
        "        \"maxAFWA_CAPE\", \"stdAFWA_TOTPRECIP\", \"avgAFWA_RAIN\", \"ggt17\", \"avgAFWA_TOTPRECIP\",\n",
        "        \"stdSMOIS4\", \"stdGUST\", \"stdSSRUN\", \"stdTDIF\", \"peakPSFC\", \"minPSFC\",\n",
        "        \"peakAFWA_MSLP\", \"minAFWA_MSLP\"]]\n",
        "\n",
        "\n",
        "X_dynamic = X_dynamic.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X_dynamic = scaler.fit_transform(X_dynamic)\n",
        "\n",
        "dynamic_reshaped_data = X_dynamic.reshape(290, 815, 30)\n",
        "print(dynamic_reshaped_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u_WEduy62gqw",
        "outputId": "f7b76644-e625-4026-ddbd-7cfda5eaedad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n"
          ]
        }
      ],
      "source": [
        "n_nodes = dynamic_reshaped_data.shape[1]\n",
        "events = dynamic_reshaped_data.shape[0]\n",
        "dynamic_adjacency_matrix = np.zeros((events, n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "for event in range(events):\n",
        "    print(event)\n",
        "    similarity_matrix = np.zeros((n_nodes, n_nodes))\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(i + 1, n_nodes):\n",
        "            similarity = mean_cosine_similarity(dynamic_reshaped_data[event, i], dynamic_reshaped_data[event, j])\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity\n",
        "\n",
        "    nearest_neighbors = np.argsort(-similarity_matrix, axis=1)[:, 1:9]\n",
        "\n",
        "    eighth_neighbors = np.sort(similarity_matrix, axis=1)[:, -8]  # Get the 8th largest value\n",
        "    average_eighth_neighbor_value = np.mean(eighth_neighbors)\n",
        "    threshold = average_eighth_neighbor_value\n",
        "\n",
        "    nearest_matrix = np.zeros((n_nodes, n_nodes), dtype=int)\n",
        "    for k in range(n_nodes):\n",
        "        nearest_matrix[k, nearest_neighbors[k]] = 1\n",
        "    dynamic_adjacency_matrix[event][(similarity_matrix > threshold) & (nearest_matrix == 1)] = 1\n",
        "\n",
        "np.save(\"/home/xus23004/Project/OPM/Results/dynamic_adjacency_matrix.npy\", dynamic_adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m-WJHRLJ6jsm"
      },
      "outputs": [],
      "source": [
        "dynamic_adjacency_matrix = np.load(\"/home/xus23004/Project/OPM/Results/dynamic_adjacency_matrix.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXK_Ag136jbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dhQTmraR2gn5"
      },
      "outputs": [],
      "source": [
        "# combine the constant and dynamic matrix, and obtain the final adjacency matrix for each event\n",
        "\n",
        "n_nodes = 815\n",
        "events = 290"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vKhSPQajHMCt"
      },
      "outputs": [],
      "source": [
        "adjacency_matrix = np.zeros((events, n_nodes, n_nodes), dtype=int)\n",
        "\n",
        "for event in range(events):\n",
        "    adjacency_matrix[event] = 0.3897679 * constant_adjacency_matrix + 0.6102321 * dynamic_adjacency_matrix[event]\n",
        "\n",
        "# There are different combination methods, or even modify the network to combine constant and dynamic information. Still working on this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iX1SeYpX2z3v"
      },
      "outputs": [],
      "source": [
        "np.save(\"/home/xus23004/Project/OPM/Results/cosntantdynamicMix_adjacency_matrix.npy\", adjacency_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "agSkj2MR2z0X"
      },
      "outputs": [],
      "source": [
        "adjacency_matrix = np.load(\"/home/xus23004/Project/OPM/Results/cosntantdynamicMix_adjacency_matrix.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFND8m6i2zxg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz2We-JU2zu5",
        "outputId": "ab34d74b-e347-4b4a-ef02-e30b295e9f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[    0.   536.   623.   741.  2653.   313.   490.  1323.   484.   815.\n",
            "  1112.   674.   205.   694.  1269.   656.   137.   460.   122.   932.\n",
            "   328.   527.   794.  3524.   582.   773.   566.  1215.   880. 16022.\n",
            "   756.   676.  1598. 15829.  1971.    65.   208.   241.   152.   163.\n",
            "   217.   107.   327.   111.   349.   153.   187.   179.   390.   652.\n",
            "   124.    79.   186.   184.   510.    85.   256.   159.   113.   196.\n",
            "    62.   113.    44.   129.   480.    69.    64.   109.   115.   278.\n",
            "   101.   302.    94.    74.    66.   134.    62.    74.   121.   110.\n",
            "    81.    68.    51.    94.    71.   780.    38.    65.    32.    57.\n",
            "    97.    50.    89.   140.   115.    79.   133.   161.   133.    92.\n",
            "   125.   132.    68.   119.    61.   127.   309.   137.   226.    60.\n",
            "   494.  4558.    89.   171.   103.   336.    74.    92.    80.   139.\n",
            "   167.    64.    75.    69.   202.    46.  2935.   180.   204.   104.\n",
            "   310.   318.   178.   404.   190.   112.   100.   421.    67.   489.\n",
            "    75.    96.   108.   128.    72.    61.    56.   187.   508.    39.\n",
            "   136.   100.    66.   374.    95.    48.    67.  1315.    52.    46.\n",
            "    78.    37.    89.    74.   147.    93.    56.    73.   109.   128.\n",
            "   102.   214.    76.   132.    80.   146.   116.   186.  2155.   133.\n",
            "    97.  2538.    99.    52.   207.    83.   118.   224.   223.    60.\n",
            "   539.    44.    44.   147.    71.    57.    39.    36.    69.   120.\n",
            "   100.  1768.   147.   114.    53.    87.    71.   107.   400. 21377.\n",
            "   313.   291.   892.   736.   141.   129.   262.   982.  1045.    98.\n",
            "  1405.   120.   948.   331.    52.  1089.   185.   169.   116.   272.\n",
            "   264.   289.    77.   209.    44.   189.   193.   248.   971.   142.\n",
            "   200.  1834.   944.   975.   165.    94.    98.  1070.   187.   643.\n",
            "   499.    96.    83.   138.   264.   228.    57.   772.   160.   373.\n",
            "   445.    43.    61.   143.   146.    37.   191.   288.    50.   101.\n",
            "    72.   316.   227.   139.   159.   185.   188.   527.    95.   839.\n",
            "   127.    82.    39.   125.  3823.    78.    70.    44.    60.    81.\n",
            "   635.]\n"
          ]
        }
      ],
      "source": [
        "# \"counts\" value for each event\n",
        "\n",
        "y = df[\"countts\"].copy()\n",
        "unique_test_groups = np.unique(group_labels)\n",
        "actual_counts = np.zeros(len(unique_test_groups)+1)\n",
        "\n",
        "for group in unique_test_groups:\n",
        "    group_actual = y[group_labels == group]\n",
        "    actual_counts[group] = np.int32(np.sum(group_actual))\n",
        "\n",
        "print(actual_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY85Rbj62zrl",
        "outputId": "5fbb5e77-36d3-469f-ff19-6c4e086149af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NaN, 1, 1, 1, 2, ..., 0, 0, 0, 0, 1]\n",
            "Length: 291\n",
            "Categories (4, int64): [0 < 1 < 2 < 3]\n",
            "0    208\n",
            "1     44\n",
            "2     35\n",
            "3      3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# classify events into different groups based on \"counts\", this part may be not used in the following code\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "bin_edges = [0, 300, 750, 5000, float('inf')]\n",
        "bin_labels = [0, 1, 2, 3]\n",
        "\n",
        "group_array = pd.cut(actual_counts, bins=bin_edges, labels=bin_labels)\n",
        "print(group_array)\n",
        "group_series = pd.Series(group_array)\n",
        "\n",
        "group_counts = group_series.value_counts()\n",
        "print(group_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PuGdJFof69rG"
      },
      "outputs": [],
      "source": [
        "# All selected 50 features, and obtained adjacency matrix, then do GCN\n",
        "\n",
        "\n",
        "# y = df[\"countts\"].copy()\n",
        "X = df[[\"land21\", \"fuseCount\", \"landTotal\", \"ohLength\", \"poleCount\",\n",
        "        \"reclrCount\", \"land22\", \"land24\", \"land23\", \"land43\", \"latwrf\",\n",
        "        \"avgHardSDI\", \"avgHardBA\", \"soilDepth\", \"stdHardBA\", \"hydNo\",\n",
        "        \"prec81\", \"avgTPA\", \"stdHardSDI\", \"avgSDI\", \"binaryts\", \"coggt27\", \"ggt27\", \"ggt22\", \"coggt22\",\n",
        "        \"stdW850\", \"maxGUST\", \"peakW850\", \"maxW850\", \"peakGUST\", \"avgAFWA_CAPE\",\n",
        "        \"avgSSRUN\", \"peakAFWA_LLWS\", \"peakSSRUN\", \"coggt17\", \"maxSSRUN\", \"stdAFWA_RAIN\",\n",
        "        \"maxAFWA_CAPE\", \"stdAFWA_TOTPRECIP\", \"avgAFWA_RAIN\", \"ggt17\", \"avgAFWA_TOTPRECIP\",\n",
        "        \"stdSMOIS4\", \"stdGUST\", \"stdSSRUN\", \"stdTDIF\", \"peakPSFC\", \"minPSFC\",\n",
        "        \"peakAFWA_MSLP\", \"minAFWA_MSLP\"]]\n",
        "\n",
        "\n",
        "X = X.fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA8OdJOqhz0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9OEJYw497h8L"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GCNForecast(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNForecast, self).__init__()\n",
        "        self.conv1_static = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv1_dynamic = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2_static = GCNConv(hidden_channels, out_channels)\n",
        "        self.conv2_dynamic = GCNConv(hidden_channels, out_channels)\n",
        "        self.fc1 = nn.Linear(2*out_channels, 16)\n",
        "        self.fc2 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x, edge_index_static, edge_index_dynamic):\n",
        "        batch_size, num_nodes, _ = x.size()\n",
        "        x = x.view(batch_size * num_nodes, -1)  # Reshape to (batch_size * num_nodes, in_channels)\n",
        "        x_static = self.conv1_static(x, edge_index_static)\n",
        "        x_dynamic = self.conv1_dynamic(x, edge_index_dynamic)\n",
        "\n",
        "        x_static = F.relu(x_static)\n",
        "        x_dynamic = F.relu(x_dynamic)\n",
        "\n",
        "        x_static = F.dropout(x_static, training=self.training)\n",
        "        x_dynamic = F.dropout(x_dynamic, training=self.training)\n",
        "\n",
        "        x_static = self.conv2_static(x_static, edge_index_static)\n",
        "        x_dynamic = self.conv2_dynamic(x_dynamic, edge_index_dynamic)\n",
        "\n",
        "        x_static = F.relu(x_static)\n",
        "        x_dynamic = F.relu(x_dynamic)\n",
        "\n",
        "        x = torch.cat((x_static, x_dynamic), dim=1).mean(dim=0)\n",
        "\n",
        "        embedding = x\n",
        "\n",
        "        x = x.view(batch_size, -1)  # Reshape back to (batch_size, num_nodes, out_channels)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x, embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN2SP6eqCu9L",
        "outputId": "c92638cf-36b7-4a76-ee27-3b1f3960006a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5])\n"
          ]
        }
      ],
      "source": [
        "print(torch.tensor([5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOu4M8kMqgrU",
        "outputId": "c84e0510-e2b9-453d-af53-d2a22e6cc76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4])\n",
            "torch.Size([1])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'criterion' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(b\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcriterion\u001b[49m(a, b))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ],
      "source": [
        "# a = torch.tensor([[0.7, 0.1, 0.2, 0]])\n",
        "# b = torch.tensor([0])\n",
        "# print(a.shape)\n",
        "# print(b.shape)\n",
        "# print(criterion(a, b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1TR2b4a27h5U"
      },
      "outputs": [],
      "source": [
        "def load_data(feature_matrix, labels):\n",
        "    # edge_index = torch.nonzero(adj_matrix).t().contiguous()\n",
        "    x = torch.tensor(feature_matrix, dtype=torch.float)\n",
        "    # y = torch.tensor(labels, dtype=torch.float).view(-1, 815, 1)  # Reshape labels to (batch_size, num_nodes, 1)\n",
        "    y = torch.tensor(labels, dtype=torch.float)    # Reshape labels to (batch_size, num_nodes, 1)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def train(model, x, edge_index_static, edge_index_dynamic, y, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out,_ = model(x, edge_index_static, edge_index_dynamic)\n",
        "    # print(\"out\", out.shape)\n",
        "    # print(\"y\", y.shape)\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()           ###########是在每一次都做backward，还是都遍历一次再做backward\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def test(model, x, edge_index_static, edge_index_dynamic, y, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out,embedding = model(x, edge_index_static, edge_index_dynamic)\n",
        "      print(out.shape)\n",
        "      loss = criterion(out, y)\n",
        "    return loss.item(), out.argmax(), embedding.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBWwpbh7ubQo",
        "outputId": "2367080e-5bf5-46c0-b6c2-03d7ce998c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1)\n",
            "[1. 0.]\n"
          ]
        }
      ],
      "source": [
        "# a = torch.tensor([[0.1, 0.7, 0.2, 0]])\n",
        "# b = np.zeros(2)\n",
        "# print(a.argmax())\n",
        "# b[0] = a.argmax()\n",
        "# print(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgnzWn_C7h1v",
        "outputId": "77453972-9dd1-44f2-e9b6-406b8083aece"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2716010/3501132699.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  constant_adjacency_matrix = torch.tensor(constant_adjacency_matrix, dtype=torch.float)\n",
            "/tmp/ipykernel_2716010/3501132699.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dynamic_adjacency_matrix = torch.tensor(dynamic_adjacency_matrix, dtype=torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1:\n",
            "Test Index: 235535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2716010/3501132699.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_loss, out, embedding = test(model, test_x, edge_index_static.to(device), edge_index_dynamic_test.to(device), torch.tensor(test_y).long().to(device), criterion)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4])\n",
            "Test Loss: 0.5180\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 2:\n",
            "Test Index: 58680\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.2057\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 3:\n",
            "Test Index: 74980\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.6882\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 4:\n",
            "Test Index: 75795\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.6923\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 5:\n",
            "Test Index: 76610\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.6961\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 6:\n",
            "Test Index: 77425\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.3925\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 7:\n",
            "Test Index: 78240\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.6848\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 8:\n",
            "Test Index: 79055\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.5173\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 9:\n",
            "Test Index: 79870\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.1187\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 10:\n",
            "Test Index: 80685\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 1.7994\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 11:\n",
            "Test Index: 81500\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 3.0233\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 12:\n",
            "Test Index: 82315\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.9350\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 13:\n",
            "Test Index: 83130\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.4092\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 14:\n",
            "Test Index: 83945\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.4328\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 15:\n",
            "Test Index: 84760\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.5945\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 16:\n",
            "Test Index: 85575\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 0.4657\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 17:\n",
            "Test Index: 86390\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 3.9928\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 18:\n",
            "Test Index: 74165\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.9846\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 19:\n",
            "Test Index: 73350\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.2057\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 20:\n",
            "Test Index: 72535\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 1.6377\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 21:\n",
            "Test Index: 65200\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.1784\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 22:\n",
            "Test Index: 60310\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.0425\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 23:\n",
            "Test Index: 61125\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.0450\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 24:\n",
            "Test Index: 61940\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 3.1590\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 25:\n",
            "Test Index: 62755\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.0704\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 26:\n",
            "Test Index: 63570\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.0747\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 27:\n",
            "Test Index: 64385\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.3997\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 28:\n",
            "Test Index: 66015\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.3808\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 29:\n",
            "Test Index: 71720\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 2.1818\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 30:\n",
            "Test Index: 66830\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 3.0129\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 31:\n",
            "Test Index: 67645\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 1.9301\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 32:\n",
            "Test Index: 68460\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 1.3443\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 33:\n",
            "Test Index: 69275\n",
            "torch.Size([1, 4])\n",
            "Test Loss: 1.9155\n",
            "out: tensor(1, device='cuda:0')\n",
            "Fold 34:\n",
            "Test Index: 70090\n"
          ]
        }
      ],
      "source": [
        "# do leave one out based on events\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float)\n",
        "constant_adjacency_matrix = torch.tensor(constant_adjacency_matrix, dtype=torch.float)\n",
        "dynamic_adjacency_matrix = torch.tensor(dynamic_adjacency_matrix, dtype=torch.float)\n",
        "\n",
        "edge_index_static = torch.nonzero(constant_adjacency_matrix).t().contiguous()\n",
        "\n",
        "\n",
        "feature_matrix = X            # feature matrix (290x815 , 50)\n",
        "y = group_array[1:]\n",
        "labels = y                    # node labels for forecasting (290x815, )\n",
        "x, y = load_data(feature_matrix, labels)\n",
        "\n",
        "\n",
        "gkf = GroupKFold(n_splits=290)\n",
        "predictions = np.zeros(290)\n",
        "embeddings = np.zeros((len(df), 16))\n",
        "\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(gkf.split(df, groups=df[\"groupLabel\"])):\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"Test Index: {test_index[0]}\")\n",
        "\n",
        "    train_x, test_x = x[train_index].view(-1, 815, 50).to(device), x[test_index].view(-1, 815, 50).to(device)\n",
        "\n",
        "    train_y = []\n",
        "    test_y = []\n",
        "    for idx in range(0, len(train_index), 815):\n",
        "        event = train_index[idx] // 815\n",
        "        train_y.append(y[event].int())\n",
        "    for idx in range(0, len(test_index), 815):\n",
        "        event = test_index[idx] // 815\n",
        "        test_y.append(y[event].int())\n",
        "\n",
        "    # print(train_y)\n",
        "    # print(test_y)\n",
        "    # print(torch.tensor(train_y))\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_y, test_y = torch.tensor(train_y, dtype=torch.int).to(device), torch.tensor(test_y, dtype=torch.int).to(device)\n",
        "\n",
        "    idx_train = train_index.reshape(-1,815)  # (289, 815)\n",
        "    idx_test = test_index.reshape(-1,815)    # (1, 815)\n",
        "\n",
        "    model = GCNForecast(in_channels=50, hidden_channels=32, out_channels=16).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()  # Use Huber loss with delta=0.22, hyperpameter tuning\n",
        "\n",
        "    for epoch in range(10):\n",
        "        loss_total = 0.0\n",
        "\n",
        "        for event in range(289):\n",
        "            idx_start = idx_train[event][0]\n",
        "            idx_event = idx_start // 815\n",
        "\n",
        "            edge_index_dynamic = torch.nonzero(dynamic_adjacency_matrix[idx_event]).t().contiguous()\n",
        "\n",
        "            # print(\"train_y:\",torch.tensor([train_y[event]]).shape)\n",
        "            loss = train(model, train_x[event, :, :].view(1, 815, 50), edge_index_static.to(device), edge_index_dynamic.to(device), torch.tensor([train_y[event]]).long().to(device), optimizer, criterion)\n",
        "            loss_total += loss\n",
        "        # print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}\")\n",
        "\n",
        "    #print(\"test_x size:\", test_x.shape)\n",
        "    #print(\"test_y size:\", test_y.shape)\n",
        "\n",
        "    test_event = idx_test[0][0] // 815\n",
        "    edge_index_dynamic_test = torch.nonzero(dynamic_adjacency_matrix[test_event]).t().contiguous()\n",
        "    test_loss, out, embedding = test(model, test_x, edge_index_static.to(device), edge_index_dynamic_test.to(device), torch.tensor(test_y).long().to(device), criterion)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(\"out:\", out)\n",
        "    predictions[test_event] = out\n",
        "    # embeddings[test_index] = embedding\n",
        "\n",
        "np.save(\"/home/xus23004/Project/OPM/Results/predictions_GCN_classification.npy\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ0D9CRy5CVp"
      },
      "outputs": [],
      "source": [
        "# evaluate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onNc0GgJVO7_"
      },
      "outputs": [],
      "source": [
        "predictions = np.load(\"/content/drive/MyDrive/predictions_GCN_classification.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsOD_LoFaPhO",
        "outputId": "2bbc6f64-4853-4d99-b5da-d3ba9e5f97a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Predicted Actual\n",
            "0            1      1\n",
            "1            1      1\n",
            "2            1      1\n",
            "3            1      2\n",
            "4            2      1\n",
            "5            1      1\n",
            "6            1      2\n",
            "7            1      1\n",
            "8            1      2\n",
            "9            1      2\n",
            "10           1      1\n",
            "11           1      0\n",
            "12           1      1\n",
            "13           1      2\n",
            "14           1      1\n",
            "15           1      0\n",
            "16           1      1\n",
            "17           1      0\n",
            "18           1      2\n",
            "19           1      1\n",
            "20           1      1\n",
            "21           1      2\n",
            "22           1      2\n",
            "23           1      1\n",
            "24           1      2\n",
            "25           1      1\n",
            "26           1      2\n",
            "27           1      2\n",
            "28           1      3\n",
            "29           1      2\n",
            "30           1      1\n",
            "31           1      2\n",
            "32           1      3\n",
            "33           1      2\n",
            "34           1      0\n",
            "35           2      0\n",
            "36           1      0\n",
            "37           1      0\n",
            "38           1      0\n",
            "39           1      0\n",
            "40           1      0\n",
            "41           1      1\n",
            "42           1      0\n",
            "43           2      1\n",
            "44           1      0\n",
            "45           1      0\n",
            "46           1      0\n",
            "47           1      1\n",
            "48           1      1\n",
            "49           1      0\n",
            "50           1      0\n",
            "51           1      0\n",
            "52           1      0\n",
            "53           1      1\n",
            "54           1      0\n",
            "55           1      0\n",
            "56           1      0\n",
            "57           1      0\n",
            "58           1      0\n",
            "59           1      0\n",
            "60           1      0\n",
            "61           1      0\n",
            "62           1      0\n",
            "63           1      1\n",
            "64           1      0\n",
            "65           1      0\n",
            "66           1      0\n",
            "67           1      0\n",
            "68           1      0\n",
            "69           1      0\n",
            "70           1      1\n",
            "71           1      0\n",
            "72           1      0\n",
            "73           1      0\n",
            "74           1      0\n",
            "75           1      0\n",
            "76           1      0\n",
            "77           1      0\n",
            "78           1      0\n",
            "79           1      0\n",
            "80           1      0\n",
            "81           1      0\n",
            "82           1      0\n",
            "83           1      0\n",
            "84           1      2\n",
            "85           1      0\n",
            "86           1      0\n",
            "87           1      0\n",
            "88           1      0\n",
            "89           1      0\n",
            "90           1      0\n",
            "91           1      0\n",
            "92           1      0\n",
            "93           1      0\n",
            "94           1      0\n",
            "95           1      0\n",
            "96           1      0\n",
            "97           2      0\n",
            "98           1      0\n",
            "99           1      0\n",
            "100          1      0\n",
            "101          1      0\n",
            "102          1      0\n",
            "103          1      0\n",
            "104          1      0\n",
            "105          1      1\n",
            "106          1      0\n",
            "107          1      0\n",
            "108          1      0\n",
            "109          1      1\n",
            "110          1      2\n",
            "111          1      0\n",
            "112          1      0\n",
            "113          1      0\n",
            "114          1      1\n",
            "115          1      0\n",
            "116          1      0\n",
            "117          1      0\n",
            "118          1      0\n",
            "119          1      0\n",
            "120          1      0\n",
            "121          1      0\n",
            "122          1      0\n",
            "123          1      0\n",
            "124          1      0\n",
            "125          1      2\n",
            "126          1      0\n",
            "127          1      0\n",
            "128          1      0\n",
            "129          1      1\n",
            "130          1      1\n",
            "131          1      0\n",
            "132          1      1\n",
            "133          1      0\n",
            "134          1      0\n",
            "135          1      0\n",
            "136          1      1\n",
            "137          1      0\n",
            "138          1      1\n",
            "139          1      0\n",
            "140          1      0\n",
            "141          1      0\n",
            "142          1      0\n",
            "143          1      0\n",
            "144          1      0\n",
            "145          1      0\n",
            "146          1      0\n",
            "147          1      1\n",
            "148          1      0\n",
            "149          1      0\n",
            "150          1      0\n",
            "151          1      0\n",
            "152          2      1\n",
            "153          1      0\n",
            "154          1      0\n",
            "155          1      0\n",
            "156          1      2\n",
            "157          1      0\n",
            "158          1      0\n",
            "159          1      0\n",
            "160          1      0\n",
            "161          1      0\n",
            "162          1      0\n",
            "163          1      0\n",
            "164          1      0\n",
            "165          1      0\n",
            "166          1      0\n",
            "167          1      0\n",
            "168          1      0\n",
            "169          1      0\n",
            "170          1      0\n",
            "171          1      0\n",
            "172          1      0\n",
            "173          1      0\n",
            "174          1      0\n",
            "175          1      0\n",
            "176          1      0\n",
            "177          1      2\n",
            "178          1      0\n",
            "179          1      0\n",
            "180          1      2\n",
            "181          1      0\n",
            "182          1      0\n",
            "183          1      0\n",
            "184          2      0\n",
            "185          1      0\n",
            "186          1      0\n",
            "187          1      0\n",
            "188          1      0\n",
            "189          1      1\n",
            "190          1      0\n",
            "191          1      0\n",
            "192          1      0\n",
            "193          1      0\n",
            "194          1      0\n",
            "195          1      0\n",
            "196          1      0\n",
            "197          1      0\n",
            "198          1      0\n",
            "199          1      0\n",
            "200          1      2\n",
            "201          1      0\n",
            "202          1      0\n",
            "203          1      0\n",
            "204          1      0\n",
            "205          1      0\n",
            "206          2      0\n",
            "207          1      1\n",
            "208          1      3\n",
            "209          1      1\n",
            "210          1      0\n",
            "211          1      2\n",
            "212          1      1\n",
            "213          1      0\n",
            "214          1      0\n",
            "215          1      0\n",
            "216          1      2\n",
            "217          1      2\n",
            "218          1      0\n",
            "219          1      2\n",
            "220          1      0\n",
            "221          1      2\n",
            "222          1      1\n",
            "223          1      0\n",
            "224          1      2\n",
            "225          1      0\n",
            "226          1      0\n",
            "227          1      0\n",
            "228          1      0\n",
            "229          1      0\n",
            "230          1      0\n",
            "231          1      0\n",
            "232          1      0\n",
            "233          1      0\n",
            "234          1      0\n",
            "235          1      0\n",
            "236          1      0\n",
            "237          1      2\n",
            "238          1      0\n",
            "239          1      0\n",
            "240          1      2\n",
            "241          1      2\n",
            "242          1      2\n",
            "243          1      0\n",
            "244          1      0\n",
            "245          1      0\n",
            "246          1      2\n",
            "247          1      0\n",
            "248          2      1\n",
            "249          1      1\n",
            "250          1      0\n",
            "251          1      0\n",
            "252          1      0\n",
            "253          1      0\n",
            "254          1      0\n",
            "255          1      0\n",
            "256          1      2\n",
            "257          1      0\n",
            "258          1      1\n",
            "259          1      1\n",
            "260          1      0\n",
            "261          1      0\n",
            "262          1      0\n",
            "263          1      0\n",
            "264          1      0\n",
            "265          1      0\n",
            "266          1      0\n",
            "267          1      0\n",
            "268          1      0\n",
            "269          1      0\n",
            "270          1      1\n",
            "271          1      0\n",
            "272          1      0\n",
            "273          1      0\n",
            "274          1      0\n",
            "275          1      0\n",
            "276          1      1\n",
            "277          1      0\n",
            "278          1      2\n",
            "279          1      0\n",
            "280          1      0\n",
            "281          1      0\n",
            "282          1      0\n",
            "283          1      2\n",
            "284          1      0\n",
            "285          1      0\n",
            "286          1      0\n",
            "287          1      0\n",
            "288          1      0\n",
            "289          1      1\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "count_results = pd.DataFrame({'Predicted': np.int32(predictions), 'Actual': group_array[1:]})\n",
        "count_results = count_results\n",
        "print(count_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6vU9yJLbEXA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkuCt5i0bEUn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebfWzsb_bEQv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoYbnxqgaPeE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1kW9pIDaPZ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJbsS-cS69oP"
      },
      "outputs": [],
      "source": [
        "def mape(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2hkKmRLNuJW",
        "outputId": "61ea18a5-13a4-4ae0-ab13-215f5b58888a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Predicted   Actual\n",
            "1        325.0    536.0\n",
            "2        300.0    623.0\n",
            "3        318.0    741.0\n",
            "4        332.0   2653.0\n",
            "5        247.0    313.0\n",
            "6        199.0    490.0\n",
            "7        163.0   1323.0\n",
            "8        204.0    484.0\n",
            "9        502.0    815.0\n",
            "10       418.0   1112.0\n",
            "11       293.0    674.0\n",
            "12       172.0    205.0\n",
            "13       639.0    694.0\n",
            "14       278.0   1269.0\n",
            "15       258.0    656.0\n",
            "16       344.0    137.0\n",
            "17       240.0    460.0\n",
            "18       164.0    122.0\n",
            "19       179.0    932.0\n",
            "20       233.0    328.0\n",
            "21       179.0    527.0\n",
            "22       480.0    794.0\n",
            "23       423.0   3524.0\n",
            "24       188.0    582.0\n",
            "25       206.0    773.0\n",
            "26       472.0    566.0\n",
            "27       375.0   1215.0\n",
            "28       447.0    880.0\n",
            "29      1540.0  16022.0\n",
            "30       230.0    756.0\n",
            "31       177.0    676.0\n",
            "32       311.0   1598.0\n",
            "33       292.0  15829.0\n",
            "34       346.0   1971.0\n",
            "35        32.0     65.0\n",
            "36       103.0    208.0\n",
            "37       201.0    241.0\n",
            "38       234.0    152.0\n",
            "39       154.0    163.0\n",
            "40       274.0    217.0\n",
            "41       163.0    107.0\n",
            "42       294.0    327.0\n",
            "43       166.0    111.0\n",
            "44       193.0    349.0\n",
            "45       202.0    153.0\n",
            "46       146.0    187.0\n",
            "47       127.0    179.0\n",
            "48       188.0    390.0\n",
            "49       227.0    652.0\n",
            "50        57.0    124.0\n",
            "51       105.0     79.0\n",
            "52       104.0    186.0\n",
            "53       142.0    184.0\n",
            "54       232.0    510.0\n",
            "55       177.0     85.0\n",
            "56       187.0    256.0\n",
            "57        59.0    159.0\n",
            "58       118.0    113.0\n",
            "59       259.0    196.0\n",
            "60       112.0     62.0\n",
            "61       144.0    113.0\n",
            "62       107.0     44.0\n",
            "63        54.0    129.0\n",
            "64       425.0    480.0\n",
            "65       206.0     69.0\n",
            "66       182.0     64.0\n",
            "67       100.0    109.0\n",
            "68       134.0    115.0\n",
            "69       204.0    278.0\n",
            "70       212.0    101.0\n",
            "71        46.0    302.0\n",
            "72        71.0     94.0\n",
            "73       259.0     74.0\n",
            "74         3.0     66.0\n",
            "75       135.0    134.0\n",
            "76       146.0     62.0\n",
            "77        34.0     74.0\n",
            "78        73.0    121.0\n",
            "79       346.0    110.0\n",
            "80       158.0     81.0\n",
            "81        64.0     68.0\n",
            "82       189.0     51.0\n",
            "83       251.0     94.0\n",
            "84       252.0     71.0\n",
            "85       364.0    780.0\n",
            "86       135.0     38.0\n",
            "87       177.0     65.0\n",
            "88       120.0     32.0\n",
            "89        70.0     57.0\n",
            "90       263.0     97.0\n",
            "91       185.0     50.0\n",
            "92       129.0     89.0\n",
            "93        89.0    140.0\n",
            "94       203.0    115.0\n",
            "95       111.0     79.0\n",
            "96       156.0    133.0\n",
            "97       335.0    161.0\n",
            "98       168.0    133.0\n",
            "99       142.0     92.0\n",
            "100      118.0    125.0\n",
            "101      115.0    132.0\n",
            "102       57.0     68.0\n",
            "103      183.0    119.0\n",
            "104       73.0     61.0\n",
            "105       75.0    127.0\n",
            "106      310.0    309.0\n",
            "107      -28.0    137.0\n",
            "108      164.0    226.0\n",
            "109      107.0     60.0\n",
            "110      246.0    494.0\n",
            "111      405.0   4558.0\n",
            "112      101.0     89.0\n",
            "113        3.0    171.0\n",
            "114       61.0    103.0\n",
            "115      268.0    336.0\n",
            "116       25.0     74.0\n",
            "117      146.0     92.0\n",
            "118       24.0     80.0\n",
            "119      159.0    139.0\n",
            "120      237.0    167.0\n",
            "121      102.0     64.0\n",
            "122      112.0     75.0\n",
            "123       55.0     69.0\n",
            "124      229.0    202.0\n",
            "125       82.0     46.0\n",
            "126      427.0   2935.0\n",
            "127      148.0    180.0\n",
            "128      332.0    204.0\n",
            "129      112.0    104.0\n",
            "130      170.0    310.0\n",
            "131      154.0    318.0\n",
            "132       95.0    178.0\n",
            "133      190.0    404.0\n",
            "134      209.0    190.0\n",
            "135      137.0    112.0\n",
            "136       61.0    100.0\n",
            "137      318.0    421.0\n",
            "138       36.0     67.0\n",
            "139      209.0    489.0\n",
            "140      139.0     75.0\n",
            "141      150.0     96.0\n",
            "142      151.0    108.0\n",
            "143      174.0    128.0\n",
            "144       60.0     72.0\n",
            "145      117.0     61.0\n",
            "146      161.0     56.0\n",
            "147      165.0    187.0\n",
            "148      344.0    508.0\n",
            "149      157.0     39.0\n",
            "150      317.0    136.0\n",
            "151      138.0    100.0\n",
            "152      190.0     66.0\n",
            "153      458.0    374.0\n",
            "154       81.0     95.0\n",
            "155       98.0     48.0\n",
            "156      162.0     67.0\n",
            "157      232.0   1315.0\n",
            "158      119.0     52.0\n",
            "159      117.0     46.0\n",
            "160      221.0     78.0\n",
            "161      182.0     37.0\n",
            "162       93.0     89.0\n",
            "163      231.0     74.0\n",
            "164      433.0    147.0\n",
            "165       96.0     93.0\n",
            "166      101.0     56.0\n",
            "167       83.0     73.0\n",
            "168      183.0    109.0\n",
            "169        4.0    128.0\n",
            "170       70.0    102.0\n",
            "171      117.0    214.0\n",
            "172      129.0     76.0\n",
            "173       91.0    132.0\n",
            "174      212.0     80.0\n",
            "175       60.0    146.0\n",
            "176       89.0    116.0\n",
            "177      359.0    186.0\n",
            "178      378.0   2155.0\n",
            "179      107.0    133.0\n",
            "180      160.0     97.0\n",
            "181      792.0   2538.0\n",
            "182      144.0     99.0\n",
            "183       57.0     52.0\n",
            "184       16.0    207.0\n",
            "185      253.0     83.0\n",
            "186      235.0    118.0\n",
            "187      324.0    224.0\n",
            "188       35.0    223.0\n",
            "189      124.0     60.0\n",
            "190      229.0    539.0\n",
            "191      152.0     44.0\n",
            "192      105.0     44.0\n",
            "193      223.0    147.0\n",
            "194       87.0     71.0\n",
            "195      148.0     57.0\n",
            "196      126.0     39.0\n",
            "197      231.0     36.0\n",
            "198       84.0     69.0\n",
            "199      128.0    120.0\n",
            "200      186.0    100.0\n",
            "201      523.0   1768.0\n",
            "202      215.0    147.0\n",
            "203      168.0    114.0\n",
            "204      -69.0     53.0\n",
            "205       99.0     87.0\n",
            "206      145.0     71.0\n",
            "207       62.0    107.0\n",
            "208      427.0    400.0\n",
            "209      395.0  21377.0\n",
            "210       80.0    313.0\n",
            "211      177.0    291.0\n",
            "212      206.0    892.0\n",
            "213      246.0    736.0\n",
            "214      -16.0    141.0\n",
            "215      130.0    129.0\n",
            "216      192.0    262.0\n",
            "217      189.0    982.0\n",
            "218      345.0   1045.0\n",
            "219       92.0     98.0\n",
            "220      257.0   1405.0\n",
            "221       95.0    120.0\n",
            "222      363.0    948.0\n",
            "223      276.0    331.0\n",
            "224       74.0     52.0\n",
            "225      185.0   1089.0\n",
            "226      119.0    185.0\n",
            "227       94.0    169.0\n",
            "228      286.0    116.0\n",
            "229      194.0    272.0\n",
            "230      265.0    264.0\n",
            "231      243.0    289.0\n",
            "232      101.0     77.0\n",
            "233       82.0    209.0\n",
            "234       63.0     44.0\n",
            "235      189.0    189.0\n",
            "236      183.0    193.0\n",
            "237      238.0    248.0\n",
            "238      424.0    971.0\n",
            "239      172.0    142.0\n",
            "240      180.0    200.0\n",
            "241      443.0   1834.0\n",
            "242      375.0    944.0\n",
            "243      637.0    975.0\n",
            "244       11.0    165.0\n",
            "245       83.0     94.0\n",
            "246       47.0     98.0\n",
            "247      282.0   1070.0\n",
            "248      147.0    187.0\n",
            "249      171.0    643.0\n",
            "250      243.0    499.0\n",
            "251       35.0     96.0\n",
            "252       19.0     83.0\n",
            "253       52.0    138.0\n",
            "254      179.0    264.0\n",
            "255      239.0    228.0\n",
            "256      166.0     57.0\n",
            "257      260.0    772.0\n",
            "258      199.0    160.0\n",
            "259      133.0    373.0\n",
            "260      271.0    445.0\n",
            "261      175.0     43.0\n",
            "262      157.0     61.0\n",
            "263      228.0    143.0\n",
            "264      195.0    146.0\n",
            "265       31.0     37.0\n",
            "266      155.0    191.0\n",
            "267      223.0    288.0\n",
            "268       67.0     50.0\n",
            "269      219.0    101.0\n",
            "270      164.0     72.0\n",
            "271      105.0    316.0\n",
            "272       27.0    227.0\n",
            "273       30.0    139.0\n",
            "274       80.0    159.0\n",
            "275      181.0    185.0\n",
            "276      287.0    188.0\n",
            "277      229.0    527.0\n",
            "278      205.0     95.0\n",
            "279      297.0    839.0\n",
            "280      184.0    127.0\n",
            "281      -37.0     82.0\n",
            "282      140.0     39.0\n",
            "283      114.0    125.0\n",
            "284      398.0   3823.0\n",
            "285       54.0     78.0\n",
            "286      264.0     70.0\n",
            "287       52.0     44.0\n",
            "288       46.0     60.0\n",
            "289      280.0     81.0\n",
            "290      243.0    635.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "unique_test_groups = np.unique(group_labels)\n",
        "prediction_counts = np.zeros(len(unique_test_groups)+1)\n",
        "actual_counts = np.zeros(len(unique_test_groups)+1)\n",
        "y = df[\"countts\"].copy()\n",
        "\n",
        "for group in unique_test_groups:\n",
        "    group_predictions = predictions[group_labels == group]\n",
        "    group_actual = y[group_labels == group]\n",
        "    prediction_counts[group] = np.int32(np.sum(group_predictions))\n",
        "    actual_counts[group] = np.int32(np.sum(group_actual))\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "count_results = pd.DataFrame({'Predicted': prediction_counts, 'Actual': actual_counts})\n",
        "count_results = count_results[1:]\n",
        "print(count_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bru6wwCTNuFb",
        "outputId": "8ecacbfd-56d3-45e9-a636-f163ca9c5c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE: 72.34745472501699\n",
            "R2: 0.03778431974550889\n"
          ]
        }
      ],
      "source": [
        "print(\"MAPE:\", mape(actual_counts[1:], prediction_counts[1:]))\n",
        "print(\"R2:\", r2_score(actual_counts[1:], prediction_counts[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "pthHqC5FNt7m",
        "outputId": "02614dfb-e831-4618-e88d-2da3790ef4de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-37-ad891f454cbc>:13: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.\n",
            "  ax.set_xlim(min_value, max_value)\n",
            "<ipython-input-37-ad891f454cbc>:14: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
            "  ax.set_ylim(min_value, max_value)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.scatter(actual_counts, prediction_counts, color='blue', label='Actual vs Predicted')\n",
        "ax.set_xlabel('Actual')\n",
        "ax.set_ylabel('Predicted')\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "# Set the x-axis and y-axis limits to be equal\n",
        "min_value = min(np.min(actual_counts), np.min(prediction_counts))\n",
        "max_value = max(np.max(actual_counts), np.max(prediction_counts))\n",
        "ax.set_xlim(min_value, max_value)\n",
        "ax.set_ylim(min_value, max_value)\n",
        "# ax.set_aspect('equal')\n",
        "plt.axis('equal')\n",
        "\n",
        "# Draw a line representing y=x\n",
        "ax.plot([min_value, max_value], [min_value, max_value], color='red', linestyle='-', label='y=x')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIM4or869k1",
        "outputId": "d57659bf-4678-441c-f19d-71c66f8389bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AE: 39.25 82.0 190.25\n"
          ]
        }
      ],
      "source": [
        "ae = np.abs(prediction_counts[1:] - actual_counts[1:])\n",
        "q25 = np.percentile(ae, 25)\n",
        "q50 = np.percentile(ae, 50)\n",
        "q75 = np.percentile(ae, 75)\n",
        "print(\"AE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1cvhJjN_oo",
        "outputId": "d6d5fe58-09ed-40b4-d745-87c439a946ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APE: 26.643418089955517 53.98981324278438 85.42191936399773\n"
          ]
        }
      ],
      "source": [
        "ape = np.abs(prediction_counts[1:] - actual_counts[1:])/actual_counts[1:] * 100\n",
        "q25 = np.percentile(ape, 25)\n",
        "q50 = np.percentile(ape, 50)\n",
        "q75 = np.percentile(ape, 75)\n",
        "print(\"APE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp0pH5veN_lO",
        "outputId": "6450a908-56a9-47b1-a441-a1aa1e19a008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRMSE: 1828.3616800266\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "y_true_mean = np.mean(actual_counts)\n",
        "\n",
        "y_true_centered = actual_counts - y_true_mean\n",
        "y_pred_centered = prediction_counts - y_true_mean\n",
        "\n",
        "crmse = np.sqrt(mean_squared_error(y_true_centered, y_pred_centered))\n",
        "\n",
        "print(\"CRMSE:\", crmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVkeMIIWzthy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W39QmbETztai"
      },
      "outputs": [],
      "source": [
        "# If we remove the three extreme events, the results of R2 and CRMSE would be much better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVFPq3u9N_gS"
      },
      "outputs": [],
      "source": [
        "new_prediction_counts = prediction_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugJaRbFjuYhs",
        "outputId": "71ed9823-342a-4fa3-d229-78a4820013bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16022.0\n",
            "1540.0\n",
            "15829.0\n",
            "21377.0\n"
          ]
        }
      ],
      "source": [
        "print(actual_counts[29])\n",
        "print(new_prediction_counts[29])\n",
        "\n",
        "print(actual_counts[33])\n",
        "print(actual_counts[209])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fLXzega69hS"
      },
      "outputs": [],
      "source": [
        "new_prediction_counts[29] = 16022\n",
        "new_prediction_counts[33] = 15829\n",
        "new_prediction_counts[209] = 21377"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCXdT6RY2glU",
        "outputId": "bd926506-34d6-4bf1-ba69-a43346a7c87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE: 71.35884879231948\n",
            "R2: 0.9194698811188228\n"
          ]
        }
      ],
      "source": [
        "print(\"MAPE:\", mape(actual_counts[1:], new_prediction_counts[1:]))\n",
        "print(\"R2:\", r2_score(actual_counts[1:], new_prediction_counts[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqv4qTnZvvxW",
        "outputId": "c4c55434-29d8-41b1-a891-f961b00c93b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRMSE: 528.9383616055909\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "y_true_mean = np.mean(actual_counts)\n",
        "\n",
        "y_true_centered = actual_counts - y_true_mean\n",
        "y_pred_centered = new_prediction_counts - y_true_mean\n",
        "\n",
        "crmse = np.sqrt(mean_squared_error(y_true_centered, y_pred_centered))\n",
        "\n",
        "print(\"CRMSE:\", crmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_5N9I4Nvvqi",
        "outputId": "276983c5-6a3d-468d-aa47-c38f14a70509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AE: 38.0 77.5 181.0\n"
          ]
        }
      ],
      "source": [
        "ae = np.abs(new_prediction_counts[1:] - actual_counts[1:])\n",
        "q25 = np.percentile(ae, 25)\n",
        "q50 = np.percentile(ae, 50)\n",
        "q75 = np.percentile(ae, 75)\n",
        "print(\"AE:\", q25, q50, q75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MZs6SaLwj1n",
        "outputId": "f7ee0883-9668-4e7e-c66d-ae43c9ef710a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APE: 24.91788410628493 53.15181518151816 83.98168394091753\n"
          ]
        }
      ],
      "source": [
        "ape = np.abs(new_prediction_counts[1:] - actual_counts[1:])/actual_counts[1:] * 100\n",
        "q25 = np.percentile(ape, 25)\n",
        "q50 = np.percentile(ape, 50)\n",
        "q75 = np.percentile(ape, 75)\n",
        "print(\"APE:\", q25, q50, q75)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
